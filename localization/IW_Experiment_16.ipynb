{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q3M12N2OEAhj",
    "outputId": "798f6bdd-b42e-454a-a297-179c07e1d348"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YOXIQLdsIGj5"
   },
   "outputs": [],
   "source": [
    "import scipy.io as scio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "OZb2r7-iIHvB"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9lwFvsYtpWSm"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "rX6kVNMOIInR"
   },
   "outputs": [],
   "source": [
    "inputspath_16 = \"C:\\\\Users\\\\BillWan\\\\Desktop\\\\Inner_Wave\\\\pre-exp\\\\inputs_win16.csv\"\n",
    "labelspath_16 = \"C:\\\\Users\\\\BillWan\\\\Desktop\\\\Inner_Wave\\\\pre-exp\\\\labels_win16.csv\"\n",
    "X_16 = pd.read_csv(inputspath_16)\n",
    "y_16 = pd.read_csv(labelspath_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kzgeMSwbIqlf",
    "outputId": "7a73ab2a-e2d8-4134-b4e7-35ab4b4163e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53440, 16)\n",
      "(6680, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_16.shape)\n",
    "print(y_16.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j1vBYGDHJYqP",
    "outputId": "b1ed938c-7276-4573-ecb9-992da3c49eb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6680, 96)\n"
     ]
    }
   ],
   "source": [
    "index = np.arange(53440)\n",
    "sub_idx1 = index[2::8]\n",
    "sub_idx2 = index[3::8]\n",
    "sub_idx3 = index[4::8]\n",
    "sub_idx4 = index[5::8]\n",
    "sub_idx5 = index[6::8]\n",
    "sub_idx6 = index[7::8]\n",
    "\n",
    "X_16 = X_16.values\n",
    "X_6v = np.empty([0, 96])\n",
    "\n",
    "for i in range(sub_idx1.shape[0]):\n",
    "    X_app = np.concatenate((X_16[sub_idx1[i]], X_16[sub_idx2[i]], X_16[sub_idx3[i]], X_16[sub_idx4[i]], X_16[sub_idx5[i]], X_16[sub_idx6[i]]))\n",
    "    X_app = np.reshape(X_app,(1,96))\n",
    "    X_6v = np.append(X_6v, X_app, axis=0)\n",
    "print(X_6v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kOHR1KnOL8CW",
    "outputId": "95c530aa-a67c-4166-fb2b-1cb1b07e56b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(np.any(np.isnan(X_6v)))\n",
    "\n",
    "where_are_NaNs = np.isnan(X_6v)\n",
    "X_6v[where_are_NaNs] = 0\n",
    "\n",
    "print(np.any(np.isnan(X_6v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qsFKPIazQCd8",
    "outputId": "01b3520f-403e-46f9-a158-4fb0568a56cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6680,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y_16.iloc[:,1].values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20a0bb11448>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd3hUZd7G8e9v0hNSKIHQi/QaIRRRXAsqKoKirmLva0VZ++666vva1oJ9XRuLWFBEdN3VVdBVsbBC6AEMRSmhJKElgRDSnvePRN8YEhLSzmRyf64rVzJnzszcAXJz8sxzzmPOOUREJHD5vA4gIiL1S0UvIhLgVPQiIgFORS8iEuBU9CIiAS7Y6wAVadWqlevSpYvXMUREGo1FixbtcM7FV3SfXxZ9ly5dSE5O9jqGiEijYWYbK7tPQzciIgFORS8iEuBU9CIiAU5FLyIS4FT0IiIBTkUvIhLgVPQiIgHOL+fRS/0qLnbk5BWyZ38+WfsL2JNbUPJ5fwHZ+ws4smMcI7u38jqmiNQRFX0j5pxj5758du7NZ09u/i9lnfVLceeTtb/wl/t+LvXsvAKqWobgqmO6cseY3oQG65c+kcZORd9I5OYXsiZ9L6nbs1m9LYfU7Tmkpuewa19+hfv7DGIjQoiLDCUmIoTmkaF0bRVVsi0ihJjS++IiQoiNDPnlc3hIEE98msor3/zEgg27eHbikXRuGdXA362I1CXzxxWmkpKSXFO9BEJRsWPjzn2kbs9h9fYcUrdnk7o9h427cn85Co8ICaJnQjS920TTMyGaNjFhxEWEEhcZQmxpYTcLDcbnsxrn+CRlO3fMWkaxg4cnDOCMQe3q6DsUkfpgZoucc0kV3acjeg/t2HuAH7bl8ENpmaem57AmPYe8gmKg5Ki8S8so+raL4awjO9ArIZreCdF0ahFZqxKvjjH9E+jfPoZJM5Zw04wlfLd+B38e24+I0KB6fV0RqXsq+npUWFTMjr35bMvaz/asPLZn57F5135S00uKfcfe/x92adUsjN4J0Vw4vDO9E6LpnRBDjzbNCA/xrlg7NI/knd8dxZS5a3jhy/Us2rib5y4YTM820Z5lEpHDp6GbGsorKCIj+0BJiWfnsT0rj21Zeb8U+vasPDJy8igu98cbHuKjZ5uSI/NeCTGln6Np1SzMm2+kmuatyeT3M5ey90Ah953Rj/OGdsSsfn+rEJHqO9TQjYr+EDJy8vgqNbOkxLPzSP+5zLPzKnwTNDosmDax4bSNDSchJpyE2JKPktsRJMSG0zwypNEWZEZOHpPfWcq363YydmBbHp4wgOjwEK9jiQgao6+R7LwCznlhPpt25QLQIiqUhJiS0k7sFEfbckXeJiY84EuvdXQ4068Yzt++Ws+UuWtYnpbFcxccycAOcV5HE5FDUNFXwDnHnbOWs2XPfqZdPpQR3Vp6OlbuT4J8xg3Hd2d41xZMmrGEs1/4jjvH9ObKY7o22t9URAKdzoapwPT5G/l3ynZuP6UXx/VqrZKvQFKXFnx88yiO69WaBz5azVWvJVc6p19EvKWiL2d52h4e+GgVJ/RuzTWjunkdx6/FRYby0sVDuO+Mvny9dgenPf013/+40+tYIlKOir6MrP0F3PDWYuKbhfHEuYPqfa56IDAzLju6K7OvH0l4iI+JL/+Xpz9bS1H56UYi4hkVfSnnHHfMWsa2PXk8d+FgmkeFeh2pUenfPpZ/TRrFuEHtePKzNVz4yn9Jz87zOpaIoKL/xdRvN/DpynTuOrU3gzs19zpOo9QsLJgnz0vksXMGsmxzFqc+/TVfpGZ4HUukydOsG2DJpt08/PFqTurbhiuP6ep1nEbNzDg3qSNHdorjxreWcPnfF3JmYjtaRIVR7BzFzlFUXPK5uBiK3M9fO4pdyW33yz4ll1Qu2YfSfRwRIUHcfVofurdu5vW3K9IoNPkTpvbk5nP6M98A8PGkUcRGBvZc+IaUV1DEQx+v5v3FWwDw+QyflUzRNDOCrOR2yXYr3U7pdqtg/5Kv16TvJSYimPevP9rvzygWaSg6M7YSzjmunp7MV2syeffakSR21Ik/jcHSzXs478X59GsXw1tXj9D0VxEOXfRNeoz+5a9/5LPVGdx9ah+VfCOS2DGOJ89LZPGmPdz27jKKNcNH5JCabNEv2riLv3ySyph+CVx+dBev48hhOm1AW+4c05t/Ld/GlLlrvI4j4tea5Juxu/flc+NbS2gXF85fzhmoU/cbqWt/040NO/bx3Bfr6NwyknOTOnodScQvNbmiLy52/H7mUnbuzee960YSG6E3XxsrM+OBs/qTtieXP7y/gg7NIznqiJZexxLxO01u6ObFeT/yRWomfxrbhwEdYr2OI7UUEuTjrxcOoXPLKK59YxHrM/d6HUnE7zSpol+4YRePz0nl9AFtuXhEZ6/jSB2JjQjh75cNJdhnXDFtoS6uJlJOkyn6nXsPcONbi+nYPIJHzh6gcfkA07FFJC9dksS2rDx+93oyBwqLvI4k4jeaRNEXFzsmz1zG7twCnr9wcMAvENJUDencnCfOHcTCDbu5Y9Zy/PEcEREvVFn0ZjbVzDLMLKXMtnfMbGnpxwYzW1rdx3rhr1+uY96aTO49oy/92mlcPpCdMagdt53ck38s3crTn6/1Oo6IX6jOEf00YEzZDc6585xzic65ROA9YHZ1H9vQ5q/fyZS5axg3qB0XDOvkZRRpIDcc352zB3fgqc/W8sGSLV7HEfFclUXvnJsH7KroPisZ6P4tMONwH9sQMnMOMOntJXRpGcVDEzQu31SYGQ9PGMCIbi24Y9ZyFvzk2T9BEb9Q2zH6UUC6c67WvyOb2TVmlmxmyZmZmbV9OoqKHbe8s4Ts/SXj8s3CmtwpA01aaLCPv100hA7NI/jd68ls2LHP60ginqlt0U+kkqP5w+Wce8k5l+ScS4qPj6/18z33n3V8u24n94/rR5+2MXWQUBqbuMhQ/n75UACumLaQPbmadilNU42L3syCgQnAO3UXp258t24HT32+hrOObM95Q3VafFPWuWUUL12SRNru/fzu9UXkFxZ7HUmkwdXmiH408INzLq2uwtSFjJw8Jr29lG6tonjgzP4alxeGdmnBY+cO5PufdnH37BWadilNTnWmV84A5gO9zCzNzK4svet8yg3bmFk7M/u4Go+tF0XFjptnLGXvgQL+euEQojQuL6XGJ7Zn8uievLc4jee/WOd1HJEGVWUTOucmVrL9sgq2bQVOq+qx9eXpz9Yw/8edPHbOQHolRDfkS0sjMOnE7mzYuY/H56yhc8sozhjUzutIIg0iYA559+Tm89r8jZwzpIMuVysVMjMeOXsAW3bv59Z3l9EuLpwhnVt4HUuk3gXMJRDiIkP5103H8L/j+3sdRfxYWHAQL148hHax4Vw9fRGbduZ6HUmk3gVM0UPJha0iQrV+qBxa86hQpl42lGLnuHzaArL2F3gdSaReBVTRi1RXt/hmvHjREDbtyuX6NxdRUKRplxK4VPTSZA3v1pJHJgzk23U7uWPWcoq0yLgEqIB5M1akJs4e0oHt2Xk89mkqwT7jL2cPxOfTuRcSWFT00uTdcHx38guLefrztQQH+XjoLJ1oJ4FFRS8C3DK6B4XFxTz/xXpCgoz7x/VT2UvAUNGLUDLH/raTe1FQ5Hhp3o8E+3zcM7aPyl4CgopepJSZcfepvSkoKmbqtz8REmzcNaa3yl4aPRW9SBlmxp/H9qWgqJgXv/qR0CAft57cy+tYIrWiohcpx8z4n3H9KSxyPPufdYQE+Zh0Yg+vY4nUmIpepAI+n/HQWQMoKHJMmbuG4CDj+uO6ex1LpEZU9CKV8PmMR88ZSGFxMY9+kkqIz8fVx3bzOpbIYVPRixxCkM944txBFBY7Hvx4NcFBxuVHd/U6lshhUdGLVCE4yMdT5yVSWFTM/f9cRXCQj4tHdPY6lki16Vo3ItUQEuTj2YmDObF3a+75IIV3Fm7yOpJItanoRaopNNjHXy8azG96xnPX7BXMWuRXyyWLVEpFL3IYfl645OgjWnH7rGX8Y+kWryOJVElFL3KYwkOCePmSJIZ3bcHkd5by0fJtXkcSOSQVvUgNRIQG8eqlQxnSuTmT3l7CJynbvY4kUikVvUgNRYUF8/fLhzGwQyw3zVjM56vTvY4kUiEVvUgtNAsLZtrlw+jTNobr3ljMl6kZXkcSOYiKXqSWYiNCmH7FMLq3bsY1ry/im7U7vI4k8isqepE6EBcZyhtXDadbqyiumr6Q79ar7MV/qOhF6kiLqJKy79g8kote+Z57Pkhh9758r2OJqOhF6lKrZmHMunYklxzVhbcWbOK4x79k2rc/UVhU7HU0acJU9CJ1LDYyhPvG9ePfN49iQPtY7vvnKk575muN3YtnVPQi9aRnm2hev3IYL108hLyCYi569Xuunp7Mxp37vI4mTUyVRW9mU80sw8xSymx7x8yWln5sMLOllTx2jJmlmtk6M7urLoOLNAZmxsn9Epgz+VhuP6UX367bwUlT5vHoJz+w70Ch1/GkiTDn3KF3MDsW2AtMd871r+D+J4As59z/lNseBKwBTgLSgIXAROfcqqpCJSUlueTk5Gp/EyKNRXp2Hn/55AdmL95C6+gw7jq1N2cmtsfn0wLkUjtmtsg5l1TRfVUe0Tvn5gG7KnliA34LzKjg7mHAOufcj865fOBtYHy1U4sEoDYx4Uz5bSKzrx9J27gIfj9zGRNe+I6lm/d4HU0CWG3H6EcB6c65tRXc1x7YXOZ2Wum2CpnZNWaWbGbJmZmZtYwl4t8Gd2rO+9eN5PFzB7Flz37OfP5bbp25jIzsPK+jSQCqbdFPpOKjeYCKfhetdJzIOfeScy7JOZcUHx9fy1gi/s/nM84Z0oEvbjuOa39zBP9ctpXjH/+SF75cz4HCIq/jSQCpcdGbWTAwAXinkl3SgI5lbncAttb09UQCVbOwYO46tTdzJh/LUUe04i+f/MDJT85j7qp0qnoPTaQ6anNEPxr4wTlX2TI7C4EeZtbVzEKB84EPa/F6IgGtS6soXrk0ielXDCMkyMfV05O5ZOoC1qbneB1NGrnqTK+cAcwHeplZmpldWXrX+ZQbtjGzdmb2MYBzrhC4EfgUWA3MdM6trMvwIoHo2J7x/PvmUdx7Rl+Wbd7DmKe/5n//tUpn10qNVTm90guaXilSYufeAzw+J5UZCzbzx9P6cPWx3byOJH6qVtMrRcQ7LZuF8dBZAxjdpzVT5q4hbXeu15GkEVLRi/g5M+P+8f0xg3v/sVJv0MphU9GLNALt4yKYPLonn/+QwacrtT6tHB4VvUgjcfnRXejTNoZ7P1xJTl6B13GkEVHRizQSwUE+Hp4wgIycAzwxZ43XcaQRUdGLNCKJHeO4ZERnXpu/gWW6Po5Uk4pepJG59ZRexDcL4w/vr9DceqkWFb1IIxMTXrKC1cqt2Uz7boPXcaQRUNGLNEKn9k/ghN4lc+u37tnvdRzxcyp6kUbIzLh/XD+cg3s/1JVF5NBU9CKNVMcWkdwyugdzV6Vrbr0ckopepBG74piu9E6I5t5/rGSv1qCVSqjoRRqxkCAfD00YQHpOHlM0t14qoaIXaeQGd2rORcM7M+27n1iRluV1HPFDKnqRAHD7mF60bBbG3e8v19x6OYiKXiQAxISHcO8ZfUnZks30+Ru9jiN+RkUvEiBOH9CW43rF88ScVLZlaW69/D8VvUiAMDP+d3x/ipzjPs2tlzJU9CIBpGOLSG4+sSefrkxnjubWSykVvUiAuWpUV3q1iea+D1eyT3PrBRW9SMD5eW791qw8npyrufWiohcJSEM6N+fC4Z2Y+u1PpGzR3PqmTkUvEqDuGNObFlEl160vKtaC4k2Zil4kQMVGhPDnM/qyPC2L1+dv8DqOeEhFLxLAzhjYlmN7xvP4nDVsz8rzOo54REUvEsDMjAfG96egqJj7/6m59U2Vil4kwHVqGcnNo3vw75TtfLYq3es44gEVvUgTcPWobvRs04x7P1xJbr7m1jc1VRa9mU01swwzSym3/SYzSzWzlWb2aCWPvdnMUkr3uaWuQovI4QkJ8vHQWQPYsmc/T3221us40sCqc0Q/DRhTdoOZHQ+MBwY65/oBj5d/kJn1B64GhgGDgLFm1qO2gUWkZpK6tGDisE68+s1PrNyqufVNSZVF75ybB+wqt/k64BHn3IHSfTIqeGgf4L/OuVznXCHwFXBWLfOKSC3cNaY3zSND+MP7KZpb34QE1/BxPYFRZvYgkAfc5pxbWG6fFOBBM2sJ7AdOA5JrnFREai02MoR7xvbl5reXMvyhz2gXF0GbmHDaxoaTEBtOQkzJ57axESTEhBMRGuR1ZKkDNS36YKA5MAIYCsw0s27OuV8OEZxzq83sL8BcYC+wDKj0XSAzuwa4BqBTp041jCUiVRk3qB37DhSxPG0P27Ly2LwrlwU/7SJrf8FB+8ZGhNA2NvyQ/xnERARjZh58J1JdVqabK9/JrAvwL+dc/9Lbn1AydPNl6e31wAjnXOYhnuMhIM0599eqXi8pKcklJ+vgX6Qh5eYXsj0rj+3ZeWzPymNbVh7p2SWff769c98ByldGREgQCbHhnDOkAzcc392b8IKZLXLOJVV0X02P6D8ATgC+NLOeQCiwo4IXbu2cyzCzTsAE4Kgavp6I1LPI0GC6xTejW3yzSvfJLywmIyfvoP8QVqRl8dinqfROiObEPm0aMLVUR5VFb2YzgOOAVmaWBtwLTAWmlk65zAcudc45M2sHvOKcO6304e+VjtEXADc453bXxzchIg0jNNhHh+aRdGge+avtBwqLGP/ct9wxazmf3HIs8dFhHiWUilRr6KahaehGpPFZk57D2Ge/4ZjurXj10iSN2zewQw3d6MxYEakTPdtEc/epvfnPDxm88f0mr+NIGSp6Eakzlx7VhVE9WvHgR6tYl7HX6zhSSkUvInXG5zOeOHcQESFB3PLOEvILi72OJKjoRaSOtY4J55GzB5KyJZspWrPWL6joRaTOndIvgfOHduTFeeuZv36n13GaPBW9iNSLe8b2pXOLSG6dubTCs26l4ajoRaReRIUF89T5R5Kec4B7Pkip+gFSb1T0IlJvEjvGccuJPfhw2VY+WLLF6zhNlopeROrV9cd3J6lzc+75IIXNu3K9jtMkqehFpF4F+Ywnz0vEAbfOXKbr4HtARS8i9a5ji0juH9ePBRt28bev1nsdp8lR0YtIg5gwuD2nD2zLk3PXsDxtj9dxmhQVvYg0CDPjoTMHEB8dxi1vLyU3v9J1iKSOqehFpMHERobwxG8H8dPOfTzw0Wqv4zQZKnoRaVAjj2jFNaO68db3m5i7Kt3rOE2Cil5EGtzvT+5J37Yx3PnecjJy8ryOE/BU9CLS4MKCg3j6/ET2HSjk9neX448LIAUSFb2IeKJHm2j+cFofvlqTyfT5G72OE9BU9CLimUuO6sxxveJ56OPVrE3P8TpOwFLRi4hnzIxHzxlIVFgwN7+9lAOFRV5HCkgqehHxVOvocB49eyCrtmUzZY4WKqkPKnoR8dzovm24YHgnXvr6R75bv8PrOAFHRS8ifuFPp/eha8sobp25jKxcLVRSl1T0IuIXIkODefr8I8nMOcAfPlihKZd1SEUvIn5jQIdYJp/Uk4+Wb+N9LVRSZ1T0IuJXrv3NEQzr0oI/vp/C2ws26ci+DqjoRcSvBPmM5y44ksSOcdw1ewVXvZasyyTUkopeRPxO65hw3rxqOH8e25dv1u3glCfn8e8V27yO1Wip6EXEL/l8xhXHdOWjScfQoXkk1725mMnvLCVrv2bkHK4qi97MpppZhpmllNt+k5mlmtlKM3u0ksdOLr0/xcxmmFl4XQUXkaahe+toZl8/kptP7MGHy7Yy5ql5fLNWc+0PR3WO6KcBY8puMLPjgfHAQOdcP+Dx8g8ys/bAJCDJOdcfCALOr21gEWl6QoJ8TD6pJ7OvG0lEaBAXvfo99324kv35umRCdVRZ9M65ecCucpuvAx5xzh0o3SejkocHAxFmFgxEAltrkVVEmrhBHeP4eNIoLj+6C9O+28Dpz3zN0s1af7YqNR2j7wmMMrPvzewrMxtafgfn3BZKjvQ3AduALOfcnMqe0MyuMbNkM0vOzMysYSwRCXThIUHce0Y/3rpqOHkFRZz9wndMmZNKQVGx19H8Vk2LPhhoDowAbgdmmpmV3cHMmlMyvNMVaAdEmdlFlT2hc+4l51yScy4pPj6+hrFEpKkY2b0Vn0w+lvGJ7XjmP+s466/f6lLHlahp0acBs12JBUAx0KrcPqOBn5xzmc65AmA2MLLmUUVEfi0mPIQpv03kbxcNZuuePE5/9hte+fpHiot1klVZNS36D4ATAMysJxAKlH8bfBMwwswiS4/2TwS07LuI1Lkx/dvy6S3HcmyPVjzw0WomvvxfNu/K9TqW36jO9MoZwHygl5mlmdmVwFSgW+mUy7eBS51zzszamdnHAM6574FZwGJgRelrvVRP34eINHHx0WG8fEkSj54zkJVbszn16a+ZmbxZl1AAzB//EJKSklxycrLXMUSkkdq8K5fb3l3G9z/tYnSfNjw8YQDx0WFex6pXZrbIOZdU0X06M1ZEAk7HFpHMuHoEfzq9D/PWZjLmqXl8krLd61ieUdGLSEDy+YyrRnXjo5uOoW1cONe+sYhXvv7R61ieUNGLSEDr0Saa968/mtMGJPDAR6v5cFnTO29TRS8iAS8kyMeU3yYyrGsLbp25lO/WNa1r5ajoRaRJCA8J4uWLk+jaKorfvb6IVVuzvY7UYFT0ItJkxEaG8NoVw2gWHsxlf19A2u6mMddeRS8iTUrb2AimXT6MvIIiLp26gD25+V5HqncqehFpcnolRPPyJUls3rWfK19LJq8gsC93rKIXkSZpeLeWPHV+Ios37WbSjCUUBfD1cVT0ItJknTagLfeO7cucVenc+2FKwF4uIdjrACIiXrrs6K5sy87jxa9+pG1sBDcc393rSHVORS8iTd6dp/QmPSuPxz5NpXV0GOcmdfQ6Up1S0YtIk+fzGY+eM4gde/O5a/YKWkWHcXyv1l7HqjMaoxcRAUKDfbxw0WB6tYnmhjcXszwtcNaiVdGLiJSKDg9h2hVDaREVyhXTFrJx5z6vI9UJFb2ISBmto8N57YphFBU7Lpm6gB17D3gdqdZU9CIi5RwR34xXLxtKenYeV05byL4DhV5HqhUVvYhIBQZ3as6zEwezYksWN7y1mIKiYq8j1ZiKXkSkEif1bcMDZw7gy9RM/vj+ikZ7QpWmV4qIHMIFwzuxPTuPZz5fS0JMOL8/uZfXkQ6bil5EpAqTR/cgPSuPZ/6zjjax4Vw4vLPXkQ6Lil5EpApmxoNn9ScjJ497PkghvlkYJ/dL8DpWtWmMXkSkGoKDfDx/4WAGdIjjphlLWLRxl9eRqk1FLyJSTZGhwUy9NIm2seFc+Voy6zL2eh2pWlT0IiKHoWWzMKZfMZxgn3HN9GT2NoI59ip6EZHD1KllJM9dMJgNO/dx53vL/X7apYpeRKQGRnRrye2n9Oaj5dt47bsNXsc5JBW9iEgN/e7Ybozu05oHP17Nkk27vY5TKRW9iEgN+XzGE+cm0iYmnBveXMzuffleR6pQlUVvZlPNLMPMUsptv8nMUs1spZk9WsHjepnZ0jIf2WZ2S12GFxHxWmxkCC9cOIQde/O55Z2lFPvhIuPVOaKfBowpu8HMjgfGAwOdc/2Ax8s/yDmX6pxLdM4lAkOAXOD9WicWEfEzAzrE8ucz+vLVmkye/2Kd13EOUmXRO+fmAeXPDLgOeMQ5d6B0n4wqnuZEYL1zbmONUoqI+LkLh3fizMR2TPlsDd+s3eF1nF+p6Rh9T2CUmX1vZl+Z2dAq9j8fmHGoHczsGjNLNrPkzMzMGsYSEfFGyWUSBtA9vhk3v72E7Vl5Xkf6RU2LPhhoDowAbgdmmplVtKOZhQLjgHcP9YTOuZecc0nOuaT4+PgaxhIR8U5UWDAvXDSY/QVF3DTDf65hX9OiTwNmuxILgGKgVSX7ngosds6l1/C1REQaje6to3l4wgAWbtjNY5+meh0HqHnRfwCcAGBmPYFQoLJBqYlUMWwjIhJIxie25+IRnXlp3o98krLd6zjVml45A5gP9DKzNDO7EpgKdCudcvk2cKlzzplZOzP7uMxjI4GTgNn1E19ExD/9aWwfBnaI5fZ3l7Fx5z5Ps5g/XqMhKSnJJScnex1DRKRWNu/KZeyz39A+LoLZ148kPCSo3l7LzBY555Iquk9nxoqI1JOOLSJ58rxBrNqWzf3/XOlZDhW9iEg9OqF3G64/7ghmLNjMrEVpnmRQ0YuI1LPfn9STEd1a8KcPVvDD9uwGf30VvYhIPQsO8vHMxCOJDg/hujcWk5NX0KCvr6IXEWkAraPDeW7ikWzalctd761o0MVKVPQiIg1keLeW3HZyLz5a0bCLlajoRUQaUNnFShY30GIlKnoRkQZUdrGSG99czK4GWKxERS8i0sAaerESFb2IiAd+Xqxk3ppMnqvnxUpU9CIiHvl5sZIn63mxEhW9iIhHGmqxEhW9iIiHyi5WcuNb9bNYiYpeRMRj3VtH88jZA+nRJpriejiRKrjOn1FERA7buEHtGDeoXb08t47oRUQCnIpeRCTAqehFRAKcil5EJMCp6EVEApyKXkQkwKnoRUQCnIpeRCTAWUMuZ1VdZpYJbKzhw1sB9Xd1oNrz93ygjHXB3/OB/2f093zgXxk7O+fiK7rDL4u+Nsws2TmX5HWOyvh7PlDGuuDv+cD/M/p7PmgcGUFDNyIiAU9FLyIS4AKx6F/yOkAV/D0fKGNd8Pd84P8Z/T0fNI6MgTdGLyIivxaIR/QiIlKGil5EJMAFTNGb2RgzSzWzdWZ2l9d5yjOzjmb2hZmtNrOVZnaz15kqYmZBZrbEzP7ldZaKmFmcmc0ysx9K/yyP8jpTeWY2ufTvOMXMZphZuB9kmmpmGWaWUmZbCzOba2ZrSz8397N8j5X+PS83s/fNLM6rfJVlLHPfbWbmzKyVF9mqEhBFb2ZBwPPAqUBfYKKZ9fU21UEKgVudc32AEcANfpgR4GZgtdchDuFp4BPnXG9SlFkAAAMSSURBVG9gEH6W1czaA5OAJOdcfyAION/bVABMA8aU23YX8Llzrgfweeltr0zj4Hxzgf7OuYHAGuDuhg5VzjQOzoiZdQROAjY1dKDqCoiiB4YB65xzPzrn8oG3gfEeZ/oV59w259zi0q9zKCmo9t6m+jUz6wCcDrzidZaKmFkMcCzwKoBzLt85t8fbVBUKBiLMLBiIBLZ6nAfn3DxgV7nN44HXSr9+DTizQUOVUVE+59wc51xh6c3/Ah0aPNiv81T0ZwjwJHAH4LczWwKl6NsDm8vcTsPPSrQsM+sCHAl8722SgzxFyT/Yul+Gvm50AzKBv5cOL71iZlFehyrLObcFeJySo7ttQJZzbo63qSrVxjm3DUoORIDWHuc5lCuAf3sdojwzGwdscc4t8zrLoQRK0VsF2/zyf1czawa8B9zinMv2Os/PzGwskOGcW+R1lkMIBgYDLzjnjgT24e1ww0FKx7nHA12BdkCUmV3kbarGzcz+SMnQ55teZynLzCKBPwJ/9jpLVQKl6NOAjmVud8APfl0uz8xCKCn5N51zs73OU87RwDgz20DJ0NcJZvaGt5EOkgakOed+/k1oFiXF709GAz855zKdcwXAbGCkx5kqk25mbQFKP2d4nOcgZnYpMBa40PnfST9HUPIf+rLSn5sOwGIzS/A0VQUCpegXAj3MrKuZhVLy5teHHmf6FTMzSsaWVzvnpnidpzzn3N3OuQ7OuS6U/Pn9xznnV0eizrntwGYz61W66URglYeRKrIJGGFmkaV/5yfiZ28Yl/EhcGnp15cC//Awy0HMbAxwJzDOOZfrdZ7ynHMrnHOtnXNdSn9u0oDBpf9O/UpAFH3pGzY3Ap9S8kM10zm30ttUBzkauJiSI+WlpR+neR2qEboJeNPMlgOJwEMe5/mV0t82ZgGLgRWU/Ix5fpq8mc0A5gO9zCzNzK4EHgFOMrO1lMwaecTP8j0HRANzS39e/uZVvkNkbBR0CQQRkQAXEEf0IiJSORW9iEiAU9GLiAQ4Fb2ISIBT0YuIBDgVvYhIgFPRi4gEuP8DuXt2AX2zPBsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X_16[8*6+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20a0bbc2888>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X_16[8*14+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oK4htg7WedX"
   },
   "source": [
    "# RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "ZUe9YMUJPjOh",
    "outputId": "6817ce3b-6638-40bb-c7e5-ed2b94e7b8a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "Best parameters: {'n_estimators': 250, 'min_samples_split': 2, 'max_depth': 16}\n",
      "MSE: 4.8566\n",
      "MAE: 0.9956\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "Round 2\n",
      "Best parameters: {'n_estimators': 300, 'min_samples_split': 2, 'max_depth': 16}\n",
      "MSE: 4.1405\n",
      "MAE: 0.9323\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "Round 3\n",
      "Best parameters: {'n_estimators': 350, 'min_samples_split': 2, 'max_depth': 16}\n",
      "MSE: 4.9058\n",
      "MAE: 0.9823\n",
      "----------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-a9bc165144cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m           }\n\u001b[0;32m     20\u001b[0m     \u001b[0mRF_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mRF_grid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train_16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mbest_est_RF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRF_grid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1529\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[0;32m   1530\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1531\u001b[1;33m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    713\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 715\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    833\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    390\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[1;32m--> 392\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1017\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1018\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    907\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    910\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    561\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    428\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ave_score_RF_MSE_final = []\n",
    "ave_score_RF_MAE_final = []\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    X_train_16, X_test_16, y_train_16, y_test_16 = train_test_split( X_6v, y, test_size=0.2)\n",
    "\n",
    "    scaler=StandardScaler()\n",
    "    X_train_16=scaler.fit_transform(X_train_16)\n",
    "    X_test_16=scaler.transform(X_test_16)\n",
    "    \n",
    "    RF = RandomForestRegressor(n_jobs=-1)\n",
    "\n",
    "    param_grid = {\n",
    "          \"n_estimators\": [250,300,350],\n",
    "          \"min_samples_split\": [0, 2, 4, 6],\n",
    "          \"max_depth\": [6,8,16]\n",
    "          }\n",
    "    RF_grid = RandomizedSearchCV(RF, param_grid, cv=5)\n",
    "    RF_grid.fit(X_train_16,y_train_16)\n",
    "    best_est_RF = RF_grid.best_estimator_ \n",
    "\n",
    "    best_est_RF.fit(X_train_16,y_train_16)\n",
    "\n",
    "    y_pred = best_est_RF.predict(X_test_16)\n",
    "    print('Round {}'.format(i+1))\n",
    "    print('Best parameters:', RF_grid.best_params_)\n",
    "    print('MSE: {:.4f}'.format(mean_squared_error(y_test_16, y_pred)))\n",
    "    print('MAE: {:.4f}'.format(mean_absolute_error(y_test_16, y_pred)))\n",
    "\n",
    "    print('----------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    ave_score_RF_MSE_final.append(mean_squared_error(y_test_16, y_pred))\n",
    "    ave_score_RF_MAE_final.append(mean_absolute_error(y_test_16, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mTmrue4oSrQW",
    "outputId": "8b61cd28-c8e6-4b1a-84af-1054e70f53fc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"average MSE: {}\".format(np.mean(ave_score_RF_MSE_final)))\n",
    "print(\"average MAE: {}\".format(np.mean(ave_score_RF_MAE_final)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n_estimators=300\n",
    "### max_depth=8\n",
    "### min_samples_split=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "MSE: 4.3509\n",
      "MAE: 0.9565\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "Round 2\n",
      "MSE: 3.7494\n",
      "MAE: 0.9138\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "Round 3\n",
      "MSE: 4.3938\n",
      "MAE: 0.9884\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "Round 4\n",
      "MSE: 5.4559\n",
      "MAE: 1.0479\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "Round 5\n",
      "MSE: 4.6418\n",
      "MAE: 0.9516\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "Round 6\n",
      "MSE: 4.6096\n",
      "MAE: 0.9794\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "Round 7\n",
      "MSE: 4.4144\n",
      "MAE: 0.9409\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "Round 8\n",
      "MSE: 5.0931\n",
      "MAE: 1.0105\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "Round 9\n",
      "MSE: 5.3469\n",
      "MAE: 1.0253\n",
      "----------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-8b28464fd92f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mRF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mRF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train_16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    390\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[1;32m--> 392\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1017\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1018\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    907\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    910\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 648\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MSE_RF = []\n",
    "MAE_RF = []\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    X_train_16, X_test_16, y_train_16, y_test_16 = train_test_split( X_6v, y, test_size=0.2)\n",
    "\n",
    "    scaler=StandardScaler()\n",
    "    X_train_16=scaler.fit_transform(X_train_16)\n",
    "    X_test_16=scaler.transform(X_test_16)\n",
    "\n",
    "    RF = RandomForestRegressor(n_jobs=-1,n_estimators=300,max_depth=32,min_samples_split=2)\n",
    "\n",
    "    RF.fit(X_train_16,y_train_16)\n",
    "\n",
    "    y_pred = RF.predict(X_test_16)\n",
    "    print('Round {}'.format(i+1))\n",
    "    print('MSE: {:.4f}'.format(mean_squared_error(y_test_16, y_pred)))\n",
    "    print('MAE: {:.4f}'.format(mean_absolute_error(y_test_16, y_pred)))\n",
    "\n",
    "    print('----------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    MSE_RF.append(mean_squared_error(y_test_16, y_pred))\n",
    "    MAE_RF.append(mean_absolute_error(y_test_16, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MSE: 4.6343185632276525\n",
      "average MAE: 0.9700883797409078\n"
     ]
    }
   ],
   "source": [
    "print(\"average MSE: {}\".format(np.mean(ave_score_RF_MSE_final)))\n",
    "print(\"average MAE: {}\".format(np.mean(ave_score_RF_MAE_final)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formal test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=16, n_estimators=350, n_jobs=-1)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_16, X_test_16, y_train_16, y_test_16 = train_test_split( X_6v, y, test_size=0.2)\n",
    "\n",
    "scaler=StandardScaler()\n",
    "X_train_16=scaler.fit_transform(X_train_16)\n",
    "X_test_16=scaler.transform(X_test_16)\n",
    " \n",
    "RF = RandomForestRegressor(n_jobs=-1,n_estimators=350,max_depth=16,min_samples_split=2)\n",
    "\n",
    "RF.fit(X_train_16,y_train_16)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5344, 96)\n",
      "(5344,)\n",
      "(1336, 96)\n",
      "(1336,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_16.shape)\n",
    "print(y_train_16.shape)\n",
    "print(X_test_16.shape)\n",
    "print(y_test_16.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred_RF = RF.predict(X_test_16)\n",
    "np.savetxt('y_pred_RF', y_pred_RF, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  3.888448275376946\n",
      "MAE:  0.9275983949452555\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE: \",mean_squared_error(y_test_16, y_pred_RF))\n",
    "print(\"MAE: \", mean_absolute_error(y_test_16, y_pred_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round\n",
    "y_1_RF = np.around(y_pred_RF)\n",
    "y_1_RF = y_1_RF.astype(int)\n",
    "np.savetxt('y_1_RF', y_1_RF, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a673dc8e88>]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# difference between prediction and label\n",
    "diff_RF = abs(y_1_RF-y_test_16)\n",
    "np.savetxt('diff_RF', diff_RF, delimiter=',')\n",
    "plt.plot(diff_RF, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6332335329341318"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# direct accuracy\n",
    "(len(diff_RF) - np.count_nonzero(diff_RF))/len(diff_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a673e37948>]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# <=5 then 0\n",
    "round_diff_RF = np.zeros(len(y_test_16))\n",
    "for i in range(len(y_test_16)):\n",
    "    if abs(y_1_RF[i]-y_test_16[i])<=5:\n",
    "        round_diff_RF[i] = 0\n",
    "    else:\n",
    "        round_diff_RF[i] = abs(y_1_RF[i]-y_test_16[i])\n",
    "# plt.subplot(122)\n",
    "plt.plot(round_diff_RF, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.968562874251497"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# +- 5 pixels are regarded as correctly-classified\n",
    "1-np.count_nonzero(round_diff_RF)/len(y_test_16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formal Test x10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ±5pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :\n",
      "MSE:  4.373240851249099\n",
      "MAE:  0.9273213486447018\n",
      "acc:  0.968562874251497\n",
      "Direct accuracy:  0.6212574850299402\n",
      "\n",
      "\n",
      "1 :\n",
      "MSE:  4.211610079229845\n",
      "MAE:  0.9571692974980774\n",
      "acc:  0.9723053892215568\n",
      "Direct accuracy:  0.6062874251497006\n",
      "\n",
      "\n",
      "2 :\n",
      "MSE:  4.738346581710139\n",
      "MAE:  0.9516524325433383\n",
      "acc:  0.9633233532934131\n",
      "Direct accuracy:  0.6474550898203593\n",
      "\n",
      "\n",
      "3 :\n",
      "MSE:  4.0287202371760635\n",
      "MAE:  0.8963962448479665\n",
      "acc:  0.9655688622754491\n",
      "Direct accuracy:  0.6294910179640718\n",
      "\n",
      "\n",
      "4 :\n",
      "MSE:  3.813932657476494\n",
      "MAE:  0.9309221321066382\n",
      "acc:  0.9730538922155688\n",
      "Direct accuracy:  0.6100299401197605\n",
      "\n",
      "\n",
      "5 :\n",
      "MSE:  4.3995645006509605\n",
      "MAE:  0.9705521428283402\n",
      "acc:  0.969311377245509\n",
      "Direct accuracy:  0.6115269461077845\n",
      "\n",
      "\n",
      "6 :\n",
      "MSE:  4.605744529564133\n",
      "MAE:  0.9958691374466075\n",
      "acc:  0.9670658682634731\n",
      "Direct accuracy:  0.5965568862275449\n",
      "\n",
      "\n",
      "7 :\n",
      "MSE:  4.79130061976774\n",
      "MAE:  0.9976692804866457\n",
      "acc:  0.968562874251497\n",
      "Direct accuracy:  0.5890718562874252\n",
      "\n",
      "\n",
      "8 :\n",
      "MSE:  5.225986913444443\n",
      "MAE:  1.031370739768382\n",
      "acc:  0.9625748502994012\n",
      "Direct accuracy:  0.6182634730538922\n",
      "\n",
      "\n",
      "9 :\n",
      "MSE:  4.2321963511801215\n",
      "MAE:  0.919860316455002\n",
      "acc:  0.9655688622754491\n",
      "Direct accuracy:  0.6235029940119761\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RF_Acc = []\n",
    "\n",
    "for i in range(10):\n",
    "    X_train_16, X_test_16, y_train_16, y_test_16 = train_test_split( X_6v, y, test_size=0.2)\n",
    "\n",
    "    scaler=StandardScaler()\n",
    "    X_train_16=scaler.fit_transform(X_train_16)\n",
    "    X_test_16=scaler.transform(X_test_16)\n",
    "\n",
    "    RF = RandomForestRegressor(n_jobs=-1,n_estimators=300,max_depth=32,min_samples_split=2)\n",
    "\n",
    "    RF.fit(X_train_16,y_train_16)\n",
    "\n",
    "    # predict\n",
    "    y_pred_RF = RF.predict(X_test_16)\n",
    "    print(i, \":\")\n",
    "    print(\"MSE: \",mean_squared_error(y_test_16, y_pred_RF))\n",
    "    print(\"MAE: \", mean_absolute_error(y_test_16, y_pred_RF))\n",
    "\n",
    "    # round\n",
    "    y_1_RF = np.around(y_pred_RF)\n",
    "    y_1_RF = y_1_RF.astype(int)\n",
    "\n",
    "    # difference between prediction and label\n",
    "    diff_RF = abs(y_1_RF-y_test_16)\n",
    "\n",
    "    # <=5 then 0\n",
    "    round_diff_RF = np.zeros(len(y_test_16))\n",
    "    for i in range(len(y_test_16)):\n",
    "        if abs(y_1_RF[i]-y_test_16[i])<=5:\n",
    "            round_diff_RF[i] = 0\n",
    "        else:\n",
    "            round_diff_RF[i] = abs(y_1_RF[i]-y_test_16[i])\n",
    "\n",
    "    # +- 5 pixels are regarded as correctly-classified\n",
    "    acc_RF = 1-np.count_nonzero(round_diff_RF)/len(y_test_16)\n",
    "    print(\"acc: \", acc_RF)\n",
    "    # direct accuracy\n",
    "    print(\"Direct accuracy: \",(len(diff_RF) - np.count_nonzero(diff_RF))/len(diff_RF))\n",
    "    print(\"\\n\")\n",
    "    RF_Acc.append(acc_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9675898203592814\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(RF_Acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ±3pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :\n",
      "MSE:  4.648662227110595\n",
      "MAE:  0.9835843397980374\n",
      "acc:  0.9281437125748503\n",
      "Direct accuracy:  0.6272455089820359\n",
      "\n",
      "\n",
      "1 :\n",
      "MSE:  5.338974503822515\n",
      "MAE:  1.0768261632398983\n",
      "acc:  0.9273952095808383\n",
      "Direct accuracy:  0.5823353293413174\n",
      "\n",
      "\n",
      "2 :\n",
      "MSE:  4.687359613971666\n",
      "MAE:  0.9956618342499705\n",
      "acc:  0.9221556886227544\n",
      "Direct accuracy:  0.6235029940119761\n",
      "\n",
      "\n",
      "3 :\n",
      "MSE:  4.5303634138737054\n",
      "MAE:  0.943377865377304\n",
      "acc:  0.9326347305389222\n",
      "Direct accuracy:  0.6175149700598802\n",
      "\n",
      "\n",
      "4 :\n",
      "MSE:  4.4420652445204825\n",
      "MAE:  0.980337026344137\n",
      "acc:  0.9244011976047904\n",
      "Direct accuracy:  0.6040419161676647\n",
      "\n",
      "\n",
      "5 :\n",
      "MSE:  4.670042713786316\n",
      "MAE:  0.9571412012734992\n",
      "acc:  0.9333832335329342\n",
      "Direct accuracy:  0.6130239520958084\n",
      "\n",
      "\n",
      "6 :\n",
      "MSE:  4.652835701799792\n",
      "MAE:  0.9762953657979856\n",
      "acc:  0.937125748502994\n",
      "Direct accuracy:  0.6077844311377245\n",
      "\n",
      "\n",
      "7 :\n",
      "MSE:  5.108863865942726\n",
      "MAE:  1.0146662013275036\n",
      "acc:  0.9281437125748503\n",
      "Direct accuracy:  0.6100299401197605\n",
      "\n",
      "\n",
      "8 :\n",
      "MSE:  4.911471629494439\n",
      "MAE:  1.0186715630372067\n",
      "acc:  0.9281437125748503\n",
      "Direct accuracy:  0.6032934131736527\n",
      "\n",
      "\n",
      "9 :\n",
      "MSE:  3.5324658827403392\n",
      "MAE:  0.9016496943328904\n",
      "acc:  0.9416167664670658\n",
      "Direct accuracy:  0.6025449101796407\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RF_Acc = []\n",
    "\n",
    "for i in range(10):\n",
    "    X_train_16, X_test_16, y_train_16, y_test_16 = train_test_split( X_6v, y, test_size=0.2)\n",
    "\n",
    "    scaler=StandardScaler()\n",
    "    X_train_16=scaler.fit_transform(X_train_16)\n",
    "    X_test_16=scaler.transform(X_test_16)\n",
    "\n",
    "    RF = RandomForestRegressor(n_jobs=-1,n_estimators=300,max_depth=32,min_samples_split=2)\n",
    "\n",
    "    RF.fit(X_train_16,y_train_16)\n",
    "\n",
    "    # predict\n",
    "    y_pred_RF = RF.predict(X_test_16)\n",
    "    print(i, \":\")\n",
    "    print(\"MSE: \",mean_squared_error(y_test_16, y_pred_RF))\n",
    "    print(\"MAE: \", mean_absolute_error(y_test_16, y_pred_RF))\n",
    "\n",
    "    # round\n",
    "    y_1_RF = np.around(y_pred_RF)\n",
    "    y_1_RF = y_1_RF.astype(int)\n",
    "\n",
    "    # difference between prediction and label\n",
    "    diff_RF = abs(y_1_RF-y_test_16)\n",
    "\n",
    "    # <=3 then 0\n",
    "    round_diff_RF = np.zeros(len(y_test_16))\n",
    "    for i in range(len(y_test_16)):\n",
    "        if abs(y_1_RF[i]-y_test_16[i])<=3:\n",
    "            round_diff_RF[i] = 0\n",
    "        else:\n",
    "            round_diff_RF[i] = abs(y_1_RF[i]-y_test_16[i])\n",
    "\n",
    "    # +- 3 pixels are regarded as correctly-classified\n",
    "    acc_RF = 1-np.count_nonzero(round_diff_RF)/len(y_test_16)\n",
    "    print(\"acc: \", acc_RF)\n",
    "    # direct accuracy\n",
    "    print(\"Direct accuracy: \",(len(diff_RF) - np.count_nonzero(diff_RF))/len(diff_RF))\n",
    "    print(\"\\n\")\n",
    "    RF_Acc.append(acc_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9303143712574851\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(RF_Acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oK4htg7WedX"
   },
   "source": [
    "# XGBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "ZUe9YMUJPjOh",
    "outputId": "6817ce3b-6638-40bb-c7e5-ed2b94e7b8a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "Best parameters: {'n_estimators': 350, 'max_depth': 6, 'learning_rate': 0.03, 'gamma': 0.1}\n",
      "MSE: 3.2562\n",
      "MAE: 0.9047\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "Round 2\n",
      "Best parameters: {'n_estimators': 250, 'max_depth': 8, 'learning_rate': 0.03, 'gamma': 0.3}\n",
      "MSE: 4.0432\n",
      "MAE: 0.7859\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "Round 3\n",
      "Best parameters: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.03, 'gamma': 0.1}\n",
      "MSE: 3.5753\n",
      "MAE: 0.7411\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "Round 4\n",
      "Best parameters: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.1, 'gamma': 0.3}\n",
      "MSE: 4.6930\n",
      "MAE: 0.8100\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "Round 5\n",
      "Best parameters: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.1, 'gamma': 0.3}\n",
      "MSE: 3.3174\n",
      "MAE: 0.7166\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "Round 6\n",
      "Best parameters: {'n_estimators': 350, 'max_depth': 8, 'learning_rate': 0.03, 'gamma': 0.3}\n",
      "MSE: 3.9824\n",
      "MAE: 0.7375\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "Round 7\n",
      "Best parameters: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.03, 'gamma': 0.1}\n",
      "MSE: 3.8607\n",
      "MAE: 0.7348\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "Round 8\n",
      "Best parameters: {'n_estimators': 350, 'max_depth': 8, 'learning_rate': 0.1, 'gamma': 0.1}\n",
      "MSE: 3.8693\n",
      "MAE: 0.7052\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "Round 9\n",
      "Best parameters: {'n_estimators': 250, 'max_depth': 6, 'learning_rate': 0.1, 'gamma': 0.1}\n",
      "MSE: 4.0920\n",
      "MAE: 0.8258\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "Round 10\n",
      "Best parameters: {'n_estimators': 350, 'max_depth': 8, 'learning_rate': 0.03, 'gamma': 0.1}\n",
      "MSE: 3.6064\n",
      "MAE: 0.7333\n",
      "----------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ave_score_XGB_MSE_final = []\n",
    "ave_score_XGB_MAE_final = []\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "  X_train_16, X_test_16, y_train_16, y_test_16 = train_test_split( X_6v, y, test_size=0.2)\n",
    "\n",
    "  scaler=StandardScaler()\n",
    "  X_train_16=scaler.fit_transform(X_train_16)\n",
    "  X_test_16=scaler.transform(X_test_16)\n",
    "\n",
    "  XGB = XGBRegressor(n_jobs=-1,colsample_bytree=0.6,objective ='reg:squarederror')\n",
    "\n",
    "  param_grid = {\n",
    "          \"n_estimators\": [250,300,350],\n",
    "          \"learning_rate\": [0.01, 0.03, 0.10],\n",
    "          \"gamma\": [0.1,0.3],\n",
    "          \"max_depth\": [6,8]\n",
    "          }\n",
    "  XGB_grid = RandomizedSearchCV(XGB, param_grid, cv=5)\n",
    "  XGB_grid.fit(X_train_16,y_train_16)\n",
    "  best_est_XGB = XGB_grid.best_estimator_ \n",
    "\n",
    "  best_est_XGB.fit(X_train_16,y_train_16)\n",
    "\n",
    "  y_pred = best_est_XGB.predict(X_test_16)\n",
    "  print('Round {}'.format(i+1))\n",
    "  print('Best parameters:', XGB_grid.best_params_)\n",
    "  print('MSE: {:.4f}'.format(mean_squared_error(y_test_16, y_pred)))\n",
    "  print('MAE: {:.4f}'.format(mean_absolute_error(y_test_16, y_pred)))\n",
    "\n",
    "  print('----------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "  ave_score_XGB_MSE_final.append(mean_squared_error(y_test_16, y_pred))\n",
    "  ave_score_XGB_MAE_final.append(mean_absolute_error(y_test_16, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mTmrue4oSrQW",
    "outputId": "8b61cd28-c8e6-4b1a-84af-1054e70f53fc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MSE: 3.829578368776089\n",
      "average MAE: 0.7694927297733323\n"
     ]
    }
   ],
   "source": [
    "print(\"average MSE: {}\".format(np.mean(ave_score_XGB_MSE_final)))\n",
    "print(\"average MAE: {}\".format(np.mean(ave_score_XGB_MAE_final)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### num_leaves=32\n",
    "### n_estimators=350\n",
    "### learning_rate=0.1\n",
    "### min_child_samples=8\n",
    "### max_depth=20\n",
    "### colsample_bytree=0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  3.722438766705641\n",
      "MAE:  0.7163124487401377\n"
     ]
    }
   ],
   "source": [
    "MSE_XGB = []\n",
    "MAE_XGB = []\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    X_train_16, X_test_16, y_train_16, y_test_16 = train_test_split( X_6v, y, test_size=0.2)\n",
    "\n",
    "    scaler=StandardScaler()\n",
    "    X_train_16=scaler.fit_transform(X_train_16)\n",
    "    X_test_16=scaler.transform(X_test_16)\n",
    "\n",
    "    XGB = XGBRegressor(n_jobs=-1,n_estimators=350,learning_rate=0.03,gamma=0.2,max_depth=8,colsample_bytree=0.6,objective ='reg:squarederror')\n",
    "\n",
    "    XGB.fit(X_train_16,y_train_16)\n",
    "\n",
    "    y_pred = XGB.predict(X_test_16)\n",
    "    print('Round {}'.format(i+1))\n",
    "    print('MSE: {:.4f}'.format(mean_squared_error(y_test_16, y_pred)))\n",
    "    print('MAE: {:.4f}'.format(mean_absolute_error(y_test_16, y_pred)))\n",
    "\n",
    "    print('----------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    MSE_XGB.append(mean_squared_error(y_test_16, y_pred))\n",
    "    MAE_XGB.append(mean_absolute_error(y_test_16, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formal test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(colsample_bytree=0.6, gamma=0.2, max_depth=8, n_estimators=350,\n",
       "             n_jobs=-1, objective='reg:squarederror')"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_16, X_test_16, y_train_16, y_test_16 = train_test_split( X_6v, y, test_size=0.2)\n",
    "\n",
    "scaler=StandardScaler()\n",
    "X_train_16=scaler.fit_transform(X_train_16)\n",
    "X_test_16=scaler.transform(X_test_16)\n",
    " \n",
    "XGB = XGBRegressor(n_jobs=-1,n_estimators=350,learning_rate=0.1,max_depth=8,gamma=0.2,colsample_bytree=0.6,objective='reg:squarederror')\n",
    "\n",
    "XGB.fit(X_train_16,y_train_16)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5344, 96)\n",
      "(5344,)\n",
      "(1336, 96)\n",
      "(1336,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_16.shape)\n",
    "print(y_train_16.shape)\n",
    "print(X_test_16.shape)\n",
    "print(y_test_16.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred_XGB = XGB.predict(X_test_16)\n",
    "np.savetxt('y_pred_XGB', y_pred_XGB, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  3.8221086993713485\n",
      "MAE:  0.6929277466487385\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE: \",mean_squared_error(y_test_16, y_pred_XGB))\n",
    "print(\"MAE: \", mean_absolute_error(y_test_16, y_pred_XGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round\n",
    "y_1_XGB = np.around(y_pred_XGB)\n",
    "y_1_XGB = y_1_XGB.astype(int)\n",
    "np.savetxt('y_1_XGB', y_1_XGB, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20933239e08>]"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dfZBd9X3f8fd3Vyt5pRivZC0GFgkBYcTwLHtbsOmkfkgs7PAgYxyjmpb6oZo202kc13JQyRgx0wx2lXFpp5k4GkzsaaiMDVRmPM4ojEPGnTQoXSGwwLZiwBhYcFgeBDYssJK+/eOeu9y9Oufe83jPOXs+rxmNds89D9/7O+d+tbr3t59j7o6IiDTDUNkFiIjI4Kjpi4g0iJq+iEiDqOmLiDSImr6ISIMsGeTBVq9e7evWrRvkIUVEam/fvn3Puft4HvsaaNNft24dU1NTgzykiEjtmdnP89qX3t4REWkQNX0RkQZR0xcRaRA1fRGRBlHTFxFpkIHO3hFpmt37p9mx5yBPH5rlpLFRtm5cz6YNE2WXJQ2mpi9SkN37p9l21wFm544AMH1olm13HQBQ45fS6O0dkYLs2HNwvuG3zc4dYceegyVVJKKmL1KYpw/NJlouMghq+iIFOWlsNNFykUFQ0xcpyNaN6xkdGV6wbHRkmK0b15dUkYg+yBUpTPvDWs3ekSpR0xcp0KYNE2ryUil6e0dEpEHU9EVEGkRNX0SkQdT0RUQaRE1fRKRB+jZ9M7vVzJ41s4dCHvu8mbmZrS6mPBERyVOcn/S/DlzSvdDM1gC/BTyRc00iIlKQvk3f3X8AvBDy0H8FvgB43kWJiEgxUr2nb2aXA9Pu/mCMdbeY2ZSZTc3MzKQ5nIiI5CRx0zez5cD1wBfjrO/uO9190t0nx8fHkx5ORERylOYn/dOBU4EHzexx4GTgfjM7Ic/CREQkf4mzd9z9AHB8+/ug8U+6+3M51iUiIgWIM2VzF/B3wHoze8rMPl18WSIiUoS+P+m7++Y+j6/LrRoRESmUfiNXRKRB1PRFRBpETV9EpEHU9EVEGkRNX0SkQdT0RUQaRE1fRKRB1PRFRBpETV9EpEHU9EVEGkRNX0SkQdT0RUQaRE1fRKRB1PRFRBpETV9EpEHU9EVEGkRNX0SkQdT0RUQapO/tEs3sVuBS4Fl3PydYtgO4DHgDeBT4pLsfKrLQuHbvn2bHnoM8fWiWk8ZG2bpxPZs2TJRdlohIJcT5Sf/rwCVdy+4BznH384B/ALblXFcqu/dPs+2uA0wfmsWB6UOzbLvrALv3T5ddmohIJfRt+u7+A+CFrmV/5e6Hg2/vA04uoLbEduw5yOzckQXLZueOsGPPwZIqEhGpljze0/8U8JdRD5rZFjObMrOpmZmZHA4X7elDs4mWi4g0Taamb2bXA4eB26LWcfed7j7p7pPj4+NZDtfXSWOjiZaLiDRN6qZvZtfS+oD3E+7u+ZWU3taN6xkdGV6wbHRkmK0b15dUkYhItfSdvRPGzC4B/gD45+7+ar4lpdeepaPZOyIi4eJM2dwFvBdYbWZPATfQmq2zDLjHzADuc/d/W2CdsW3aMKEmLyISoW/Td/fNIYu/VkAtIiJSMP1GrohIg6jpi4g0iJq+iEiDqOmLiDRIqimbUh1lBswp3E6kftT0a6wdMNfOG2oHzAGFN98yjy0i6entnRorM2BO4XYi9aSmX2NlBswp3E6kntT0a6zMgDmF24nUk5p+jZUZMKdwO5F60ge5NVZmwJzC7UTqyQaZijw5OelTU1MDO56IyGJgZvvcfTKPfentHRGRBlHTFxFpEDV9EZEGUdMXEWkQNX0RkQaJc7vEW2ndAP1Zdz8nWLYKuB1YBzwO/I67v1hcmdWhkDERqbM4P+l/Hbika9l1wPfd/Qzg+8H3i147ZGz60CzOmyFju/dPl12aiEgsfZu+u/8AeKFr8RXAN4KvvwFsyrmuSlLImIjUXdr39N/h7s8ABH8fH7WimW0xsykzm5qZmUl5uGpQyJiI1F3hH+S6+053n3T3yfHx8aIPVyiFjIlI3aVt+v9oZicCBH8/m19J1aWQMRGpu7RN/27g2uDra4Hv5FNOtW3aMMFNV57LxNgoBkyMjXLTledq9o6I1EacKZu7gPcCq83sKeAG4EvAt8zs08ATwMeKLLJKNm2YUJMXkdrq2/TdfXPEQx/IuRYRESmYfiNXRKRB1PRFRBpETV9EpEHU9EVEGkT3yF2EeoXCKTBOpDh1eH2p6S8y7VC4dkZQOxSuLeqxql2YInXT67VXpdeX3t5ZZHqFwikwTqQ4dXl96Sf9RSZNKJwC40Syq0sgo37SX2R6hcIpME6kOHV5fanpLzK9QuEUGCdSnLq8vvT2ziLT/sCo1wyCqs8uEKmjOK+9KjB3H9jBJicnfWpqamDHExFZDMxsn7tP5rEvvb0jItIgavoiIg2ipi8i0iBq+iIiDaKmLyLSIJmmbJrZ7wOfARw4AHzS3V/LozBphjIDqoo89u7902y/+2EOzc4BsHL5CDdcdnblpu9Jb3GvkToErbWlbvpmNgH8B+Asd581s28BVwNfz6k2WeTKDKgq8ti790+z9dsPMnf0zenQL746x9Y7Hsxl/zIYca+RugSttWV9e2cJMGpmS4DlwNPZS5KmKDOgqshj79hzcEHDb5s74pUL35Joca+RugSttaVu+u4+Dfwx8ATwDPCSu/9V93pmtsXMpsxsamZmJn2lsuiUGVBV5LEVbrc4xL1G6hK01pa66ZvZSuAK4FTgJGCFmV3TvZ6773T3SXefHB8fT1+pLDplBlQVeexe+6ha+JZEi3uN1CVorS3L2zu/CfzM3WfcfQ64C3hPPmVJE5QZUFXksbduXM/IkB2zfGTYKhe+JdHiXiN1CVpryzJ75wngIjNbDswCHwAUrCOxlRlQVeSx2/vQ7J16i3uN1CVorS1T4JqZ3Qh8HDgM7Ac+4+6vR62vwDURkeTyDFzLNE/f3W8AbsijEBERKZ5+I1dEpEHU9EVEGkRNX0SkQdT0RUQaRE1fRKRBGn9j9H7peHVKzxuUXmOSx3h17+N9Z45z709mFvU5KPo6a+9/+tAsw2YccWdikY5lmCLGt669odE3Ru9Ox4PWb9LddOW5bNow0ffxJuo1JkDm8Qrbf7fFdg6Kvs56jeliG8swRYzvoHuDboyek37peHVLzxuEXmOSx3iF7aPbYjsHRV9nvcZ0sY1lmCLGt869odFv7/RLx6tbet4gpBmTJOMVd93FdA6Kvs767WcxjWWYIsa3zr2h0T/p90vHq1t63iD0GpM8xivuuovpHBR9nfXbz2IayzBFjG+de0Ojm36/dLy6pecNQq8xyWO8wvbRbbGdg6Kvs15jutjGMkwR41vn3tDot3f6pePVLT1vEOKMSZbxCtv/Yp+9U/R11rn/Js7eKWJ869wbGj17R0SkDjR7R0REUlHTFxFpEDV9EZEGUdMXEWkQNX0RkQbJNGXTzMaAW4BzAAc+5e5/l0dhaWQNQCpy+yqHM0XVVqeQriqPbz9l1V7nMZP0st4Y/RvA/3H3W8xsKbDc3Q9FrV/klM2sAUhFbg/Zg8iKElX3R981wZ37pmsR0lXnYLyyaq/zmDVRJaZsmtlxwG8AXwNw9zd6NfyiZQ1AKnL7KoczRdW2a++TtQnpqvL49lNW7XUeM8kmy3v6pwEzwJ+b2X4zu8XMVnSvZGZbzGzKzKZmZmYyHK63rAFIRW5f5XCmqBqO9PkfYBVqb6vy+PZTVu11HjPJJkvTXwK8E/hTd98AvAJc172Su+9090l3nxwfH89wuN6yBiAVuX2Vw5miahg2S7VdGao8vv2UVXudx0yyydL0nwKecve9wfd30PpHoBRZA5CK3L7K4UxRtW2+cE1tQrqqPL79lFV7ncdMskk9e8fdf2FmT5rZenc/CHwA+FF+pSWTNQBpENtXcaZEr7onT1lVi9k7dQ6/Kqv2Oo+ZZJN19s4FtKZsLgUeAz7p7i9Gra/ANRGR5PKcvZNpnr67PwDkUoiIiBRPv5ErItIgavoiIg2ipi8i0iBq+iIiDdLoe+TGVeVgqrS1dW73ttERzODQq3OFPb+4x8trrPPYT5x95HltDOo6271/mu13P8yh2TkAVi4f4YbLzi617n77KPs1WPbx86R75PZR5WCqtLWFbdcp7+cX93iQTzBdHucszj7yvDYGdZ3t3j/N1m8/yNzRha/7kWFjx1Xnl1J3v32U/Ros+/hQkcC1pqhyMFXa2sK2S7qPJOIeL6+xzmM/cfaR57UxqOtsx56DxzR8gLkjXlrd/fZR9muw7OPnTW/v9FHlYKq0tcWpPc/nl/V4SWvJ45zF2Uee18agrrM8x7nXNnmOddmvwbKPnzf9pN9HlYOp0tYWp/Y8n1/c4+U11nnsJ84+8rw2BnWd9dpfWXX320fZr8Gyj583Nf0+qhxMlba2sO2S7iOJuMfLa6zz2E+cfeR5bQzqOtu6cT0jQ8cmqI4MW2l199tH2a/Bso+ft+Ht27cP7GA7d+7cvmXLloEdLw9nnngcJ68c5cD0S/zqtcNMjI3yxcvOKv1D3Cy1dW83NjrC6NJhXp87Wsjzi3u8vMY6j/3E2Uee18agrrMzTzyOtauWc99jz/Pa4aNAa/bOH30k3YeSgxjrsl+DZR8f4MYbb3xm+/btO/PYl2bviIhUnGbviIhIKmr6IiINoqYvItIgavoiIg2ipi8i0iCZfyPXzIaBKWDa3S/NXlK0XqFH3Y+978xx7v3JzDEBX2nDxaoWuBQ3NCuPQLY8tuuud8jgqMNE17lKM7ZFhrRB+H1k8w4tS1Nr2PHb9U53/LbosBmbL1zDf950bqpj/eHuA+za+yRH3DFg+dJhXnnjSKz7Jg8ikC5s+dTPX5ivediMi05byePPzxby+q1ab+gn85RNM/scrVsmHtev6WeZstkr9AiODeqKK21AWZmha3FDs/IMZMuy3UffNcHtf/9kaOZLmCRjm9e5CdvPyJCBtXJp4jyftKFlSUWd/yGD4SFbUG+nay5am7jx/+HuA/zFfU/0XS9szAcRSPfRd01w577pBcuHgKMp6k1jUL2hMlM2zexk4Ldp3Ry9UL1Cj/oFevWSNqCszMCluKFZeQayZdlu1974DT/usbLWGmc/c0f9mAba6/mkDS1LKur8H3UiGz7Arr1PJj5W3G3CxnwQgXS79j55zPJ+DT9LHXHrqnIYW9a3d24GvgC8NWoFM9sCbAFYu3Zt6gMVGXqUNqCsrMCluKFZeQeypd3uSIr/TcYd27zOTZL1ez2fQVwTaY+R5jwk2aa7rkEE0qV5TlnqiLuPKoexpf5J38wuBZ5193291nP3ne4+6e6T4+PjaQ/XM/Qoa/BR2oCysgKX4oZm5R3Ilna7YTs266WfuGNbdEhbmF7PZxDXRNpjpDkPSbbprmsQgXRpnlOWOuLuo8phbFne3rkYuNzMHge+CbzfzP4il6pC9Ao96hfo1UvagLIyA5fihmblGciWZbvNF64JrTdKkrEtMqRtZMgYGV5Yd6/nkza0LKmo8z9kHFNvp80Xrkl8rLjbhI35IALpNl+45pjlcZpaXq/fqvWGOFK/vePu24BtAGb2XuDz7n5NTnUdo/2hSK9PyYuavRPn2IPUPm6/2SNp6y5iu8lTVhUyeyevcxO1n7jPZ5Czd3qd/3a9ec3eaW+TZvZOnq+bftdWWbN3qtYb4sglcK2j6Rc2e0dEpKnynL2Ty52z3P1vgL/JY18iIlIc/UauiEiDqOmLiDSImr6ISIOo6YuINEguH+QuBklDk+Ks3y8gavrQbOi0t16PQ/TU1DID1ZKu128MBi1tmF+cc/+20RHeOHyEV+fevCftb5934oJ9rHv7KPc99uL8FMPOKZZRQXC9pmzGCSXrNc6dIWthUz7jnt+ipzHGCcnLGujX69hR03arHMKme+SSPDQpzvpJAqLiPh4WABa2j0EHqiUN2gp7PEkdecsa5hfn3KdxzUVrmTxlVWgQ3BF3uuN3wgLXoq6pXuMcFbLWDmxLc36LOK9xQ/K65VFLr9DDj/+TNYnGO47KBK4tFklDk+KsnyQgKu7jYQFgYfsYdKBa0qCtXgF5ZYRVZQ3zi3Pu09i198nIILiw/LqwwLWoa6rXOEeFrLWXpzm/RZzXuCF53fKopVfoYdLxHjS9vUPy0KQ4y9MGRGUJkOp37H6P57Vdv/XSHqcoeYRmxTn3SR1xz2VfUddU0mu0vTzt+c37vGbZX9Zaem2fdLwHTT/pkzw0Kc7ytAFRWQKk+h273+N5bddvvbTHKUoeYX5xzn1Sw2a57Cvqmkp6jbaXpz2/eZ/XLPsrMqQx6XgPmpo+yUOT4qyfJCAq7uNhAWBh+xh0oFrSoK1eAXllhFVlDfOLc+7T2HzhmsgguLD8urDAtahrqtc4R4WstZenOb9FnNe4IXnd8qilV+hh0vEetOHt27cP7GA7d+7cvmXLloEdL64zTzyOk1eOcmD6JX712mEmxkb54mVnRX7oEmf9qHV+932/Pr/8l68dZtgMh1iPb7/8bD541gkL9nnFBSfx/K/eiFV32uebdLt+63U+HjYGg57l0KvesMf6jXn3NmOjIwwZ8+8Br1w+wlXvOnnBPs6bOI6nD72G0/pJ8RPBh6Zhx99++dlsPPsE7nvseV47/OaMoJuuPO+Y66P7mopzvt9/5jt47lev8/D0y8fU02+84jxe5HnL6zUS59hrVy0/5hz80UfOTTzecdx4443PbN++fWemogOavSMiUnGavSMiIqmo6YuINIiavohIg6jpi4g0iJq+iEiDpG76ZrbGzO41sx+b2cNm9nt5FiYiIvnLEsNwGPiP7n6/mb0V2Gdm97j7j3KqLbHO5EYD2pNRw25a3Qpr+iGzQfLhkMG7T1vFw0//cj41r9e2cRI2OxP4OoWlKHav233c7nWWjwyxbGSYF1+dW/Bc28s7b/wO0TdR75UG2e/m5RB+I/HOY40MwRFv7SfqBt3dNYTduD5JCmb3Y1E3ZE+TjJo26bK9rDtVNGkCZNR11b759/1PHFpwTf+LC9dG3hC91zWa9EbvcV57YcmqYx3nu9f11ys9M2p/UddJ5/r9+kSW59nrei5TbvP0zew7wP9w93ui1ilynn6/ZMORYWPHVefPn5TP3f4AR2Puu3vbOAmbYQl83dopilHrto8LxNpfaO0RiYxRaYBJ9tudZhh1rG7XdPyiT7/z1i8lEo5Nwex8rNe4ZUlGTZJ0GSf5MaqmTnGvq26d451kX53XfS9xXntZrjVINoadkqSltmuNes55PM+0aZt5ztPPpemb2TrgB8A57v5y1HpFNv2Lv/TXTPcJNJoYG+Vvr3t/rHWTbtt+PG4t0Prp7IS3vaXnuhNBXkfSeuNo/7QzaMNmPHrTh4F4YxVVZ6+xiTtucc7boMeps6ZOaa5bWDjeSfcVVUvSfZV1rUHy11CW8Y/zPOOMabc8m37mlE0z+zXgTuCzYQ3fzLYAWwDWrl2b9XCR4iTYxU15TLNtmpTFOCmKRSbzlfUi7DxunOeXJrUw7rjlkYyat7xTKsPqTzM+WdYp61qD5OOWZfzjPM+y0zYzzd4xsxFaDf82d78rbB133+nuk+4+OT4+nuVwPcVJsIub8phm2zQpi3FSFJMkPSaVR6Jn1uPGeW69UguzJmTmkYyat7xTKsPqT5MemmWdsq41SP4ayjL+cZ5n2WmbWWbvGPA14Mfu/pX8SkqnX7LhyLAtSAFM8sS7t42TsBmWwNetnaIYtW77uHH3F7qPiETGqDTAJPvtTjOMOla3zhTHfuetX0pkv4TMXuOWJRk1SdJlnOTHqJo6pb0OwlIz4+yr87rvJc5rL8u1BsnGsFOStFTo/ZzzeJ5VSNvM8vbOxcC/BA6Y2QPBsv/k7t/LXlZy7Q9G4szeaf+dZvZO53GiZly0v447eyds3bCZBEXM3pk8ZVWps3e6xzNqtkNnnWFj3uuxuLN3ep3bsONHjWvUuGSdvdPruko6e6ffNZpk9k7c1157DMuavRN2DpLM3kn6PBf97J04lLIpIpKcUjZFRCQVNX0RkQZR0xcRaRA1fRGRBlHTFxFpkMy/kVu0XqFQvaxYOswrb4TnX3RPmbtz31Pz09yABVOx+lm2ZIjXDx/t+evXZxy/glffOJrqV+jbU0kff352fgrYy7NzC3KDzjh+BTO/fCN0jDqnva17+yj/99EX5p/b0mFjxbIlvPhqsrEF5qfGRW07bK2pmknFHfvu/benJ06esmrBVNwk+0jDgPecvmrBVMm2zmm1YVMEk+h1fRnw68ev4KfPvhJrX+1rolctcdYJ26Y9RTQqmAxa4wLMT83MKmpqZ/f02OVLhxaM0XHLhnn59WRZQEuHjSVDFll7u5Z+U0fLVOkpm2kDpkSkPBefvor7n3gpdbhaFmmD2YqWNmitrTFTNnfsOaiGL1Izf/voC6U0fIC5o165hg8wO3eEHXsOll0GUPGmX3YwkYhIXqrSzyrd9MsOJhIRyUtV+lmlm36WoDERKcfFp6/KFK6WRdpgtqJVIWitrdJNf9OGCXZ87HzGRkcSb7tiafRF144/nRgb5ZqL1jI6snAYklwyy5YMLdhnmDOOXzF/I4ekhqz1IpoYG8VozQroPmlnHL8icoza/2ZOjI1y8emrFjy3pcPGyuXJx5agjl7bpn3dxd2se/9D1rpD1M0fv+CY8xl3H2kY7SZ37DGXjwzNj1H7+kh7yF7Xl9G6BuJqXxO9aomzTtg211y0ltv+zbu56cpz56/57n0sHxman8GTh85rfMfHzmfHVefPH7vztd49RsctS/4P09Jh61l7u5b268OCY2f5EDdvlZ69IyIiDZq9IyIi+VLTFxFpEDV9EZEGUdMXEWkQNX0RkQbJFLhmZpcA/w0YBm5x9y/lUlWHVv7OA+SUzSQiUpplS4b48kfPK3X6Zuqf9M1sGPgT4EPAWcBmMzsrr8Kg1fA/e7savogsDq8fPsrnvvUAu/dPl1ZDlrd3/inwiLs/5u5vAN8ErsinrJaqBBSJiOTlqJfb27I0/QngyY7vnwqWLWBmW8xsysymZmZmEh2gKgFFIiJ5KrO3ZWn6Yb+hfcyv97r7TnefdPfJ8fHxRAeoSkCRiEieyuxtWZr+U8Caju9PBp7OVs5CVQkoEhHJy5CV29uyNP3/B5xhZqea2VLgauDufMpq2bRhgps/fgE5ZjOJiJRm2ZIhvvI7F5Q6eyf1lE13P2xm/x7YQ2vK5q3u/nBulQU2bZioTDqdiEjdZZqn7+7fA76XUy0iIlIwvXEiItIgavoiIg2ipi8i0iBq+iIiDTLQ2yWa2Qzw85Sbrwaey7GcQalj3XWsGVT3INWxZqhn3auBFe6e7LdbIwy06WdhZlN53SNykOpYdx1rBtU9SHWsGepZd9416+0dEZEGUdMXEWmQOjX9nWUXkFId665jzaC6B6mONUM968615tq8py8iItnV6Sd9ERHJSE1fRKRBatH0zewSMztoZo+Y2XVl19NmZmvM7F4z+7GZPWxmvxcsX2Vm95jZT4O/VwbLzcz+e/A8fmhm7yyx9mEz229m3w2+P9XM9gY13x7EZWNmy4LvHwkeX1dizWNmdoeZ/SQY83fXZKx/P7g+HjKzXWb2liqOt5ndambPmtlDHcsSj6+ZXRus/1Mzu7aEmncE18gPzex/m9lYx2PbgpoPmtnGjuUD7TFhdXc89nkzczNbHXyf71i7e6X/0IptfhQ4DVgKPAicVXZdQW0nAu8Mvn4r8A+0bhL/X4DrguXXAV8Ovv4w8Je07jp2EbC3xNo/B/wv4LvB998Crg6+/irw74Kvfxf4avD11cDtJdb8DeAzwddLgbGqjzWtW4j+DBjtGOd/XcXxBn4DeCfwUMeyROMLrAIeC/5eGXy9csA1fxBYEnz95Y6azwr6xzLg1KCvDJfRY8LqDpavoRVX/3NgdRFjPfAXQYrBeTewp+P7bcC2suuKqPU7wG8BB4ETg2UnAgeDr/8M2Nyx/vx6A67zZOD7wPuB7wYX03MdL5T5MQ8uwHcHXy8J1rMSaj4uaJ7WtbzqY92+l/SqYPy+C2ys6ngD67oaaKLxBTYDf9axfMF6g6i567GPALcFXy/oHe2xLqvHhNUN3AGcDzzOm00/17Guw9s7sW7AXrbgv+EbgL3AO9z9GYDg7+OD1aryXG4GvgAcDb5/O3DI3Q+H1DVfc/D4S8H6g3YaMAP8efC21C1mtoKKj7W7TwN/DDwBPENr/PZR/fFuSzq+lRj3Dp+i9VMyVLxmM7scmHb3B7seyrXuOjT9WDdgL5OZ/RpwJ/BZd3+516ohywb6XMzsUuBZd9/XuThkVY/x2CAtofXf4T919w3AK7TebohSibqD98CvoPV2wknACuBDIatWbbz7iaqzMvWb2fXAYeC29qKQ1SpRs5ktB64Hvhj2cMiy1HXXoekXfgP2LMxshFbDv83d7woW/6OZnRg8fiLwbLC8Cs/lYuByM3sc+Catt3huBsbMrH0ntc665msOHn8b8MIgC+6o4yl33xt8fwetfwSqPNYAvwn8zN1n3H0OuAt4D9Uf77ak41uJcQ8+1LwU+IQH7330qK0KNZ9O6weDB4PX5snA/WZ2Qo/6UtVdh6Zf+A3Y0zIzA74G/Njdv9Lx0N1A+5P0a2m9199e/q+CT+MvAl5q/9d5UNx9m7uf7O7raI3lX7v7J4B7gasiam4/l6uC9Qf+k5u7/wJ40szWB4s+APyICo914AngIjNbHlwv7borPd4dko7vHuCDZrYy+F/OB4NlA2NmlwB/AFzu7q92PHQ3cHUwQ+pU4Azg76lAj3H3A+5+vLuvC16bT9GaJPIL8h7roj+syOkDjw/TmhnzKHB92fV01PXPaP136ofAA8GfD9N6D/b7wE+Dv1cF6xvwJ8HzOABMllz/e3lz9s5ptF4AjwDfBpYFy98SfP9I8PhpJdZ7ATAVjPduWjMWKj/WwI3AT4CHgP9Ja/ZI5cYb2EXrc4e5oOl8Os340nof/ZHgzydLqPkRWu91t1+TX+1Y//qg5oPAhzqWD7THhNXd9fjjvPlBbq5jrRgGEZEGqfuYazIAAAAuSURBVMPbOyIikhM1fRGRBlHTFxFpEDV9EZEGUdMXEWkQNX0RkQZR0xcRaZD/D4xgRMr4yTjHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# difference between prediction and label\n",
    "diff_XGB = abs(y_1_XGB-y_test_16)\n",
    "np.savetxt('diff_XGB', diff_XGB, delimiter=',')\n",
    "plt.plot(diff, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7859281437125748"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# direct accuracy\n",
    "(len(diff_XGB) - np.count_nonzero(diff_XGB))/len(diff_XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x209332b0388>]"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# <=5 then 0\n",
    "round_diff_XGB = np.zeros(len(y_test_16))\n",
    "for i in range(len(y_test_16)):\n",
    "    if abs(y_1_XGB[i]-y_test_16[i])<=5:\n",
    "        round_diff_XGB[i] = 0\n",
    "    else:\n",
    "        round_diff_XGB[i] = abs(y_1_XGB[i]-y_test_16[i])\n",
    "# plt.subplot(122)\n",
    "plt.plot(round_diff_XGB, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.969311377245509"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# +- 5 pixels are regarded as correctly-classified\n",
    "1-np.count_nonzero(round_diff_XGB)/len(y_test_16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formal Test x10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ±5pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :\n",
      "MSE:  4.275323637674735\n",
      "MAE:  0.7939051622803697\n",
      "acc:  0.9603293413173652\n",
      "Direct accuracy:  0.7649700598802395\n",
      "\n",
      "\n",
      "1 :\n",
      "MSE:  3.5704219454371646\n",
      "MAE:  0.6625167116924318\n",
      "acc:  0.9723053892215568\n",
      "Direct accuracy:  0.7754491017964071\n",
      "\n",
      "\n",
      "2 :\n",
      "MSE:  4.338800923595393\n",
      "MAE:  0.7725406731450986\n",
      "acc:  0.968562874251497\n",
      "Direct accuracy:  0.7559880239520959\n",
      "\n",
      "\n",
      "3 :\n",
      "MSE:  4.402511939733385\n",
      "MAE:  0.7508904387850961\n",
      "acc:  0.9730538922155688\n",
      "Direct accuracy:  0.7664670658682635\n",
      "\n",
      "\n",
      "4 :\n",
      "MSE:  3.947312489773974\n",
      "MAE:  0.713660697759447\n",
      "acc:  0.9730538922155688\n",
      "Direct accuracy:  0.7747005988023952\n",
      "\n",
      "\n",
      "5 :\n",
      "MSE:  3.3471086658384155\n",
      "MAE:  0.6790591241669155\n",
      "acc:  0.9738023952095809\n",
      "Direct accuracy:  0.7687125748502994\n",
      "\n",
      "\n",
      "6 :\n",
      "MSE:  3.357666765563333\n",
      "MAE:  0.6387633253223525\n",
      "acc:  0.9752994011976048\n",
      "Direct accuracy:  0.7986526946107785\n",
      "\n",
      "\n",
      "7 :\n",
      "MSE:  3.9978386560263908\n",
      "MAE:  0.7349168299111778\n",
      "acc:  0.968562874251497\n",
      "Direct accuracy:  0.7642215568862275\n",
      "\n",
      "\n",
      "8 :\n",
      "MSE:  4.324153267084808\n",
      "MAE:  0.7377067981232069\n",
      "acc:  0.969311377245509\n",
      "Direct accuracy:  0.7724550898203593\n",
      "\n",
      "\n",
      "9 :\n",
      "MSE:  3.5873843952107425\n",
      "MAE:  0.6725355333196903\n",
      "acc:  0.9715568862275449\n",
      "Direct accuracy:  0.782185628742515\n",
      "\n",
      "\n",
      "10 :\n",
      "MSE:  3.9193272695268924\n",
      "MAE:  0.7354524179088499\n",
      "acc:  0.9715568862275449\n",
      "Direct accuracy:  0.7627245508982036\n",
      "\n",
      "\n",
      "11 :\n",
      "MSE:  5.689790764326009\n",
      "MAE:  0.8655586187577177\n",
      "acc:  0.9588323353293413\n",
      "Direct accuracy:  0.7627245508982036\n",
      "\n",
      "\n",
      "12 :\n",
      "MSE:  4.860751070366593\n",
      "MAE:  0.7755861772882368\n",
      "acc:  0.9610778443113772\n",
      "Direct accuracy:  0.7866766467065869\n",
      "\n",
      "\n",
      "13 :\n",
      "MSE:  3.582690158619275\n",
      "MAE:  0.6575378474896539\n",
      "acc:  0.9715568862275449\n",
      "Direct accuracy:  0.7844311377245509\n",
      "\n",
      "\n",
      "14 :\n",
      "MSE:  2.9217185412913964\n",
      "MAE:  0.6590439076507519\n",
      "acc:  0.9767964071856288\n",
      "Direct accuracy:  0.7694610778443114\n",
      "\n",
      "\n",
      "15 :\n",
      "MSE:  3.451908498643331\n",
      "MAE:  0.6905348268811574\n",
      "acc:  0.9708083832335329\n",
      "Direct accuracy:  0.7649700598802395\n",
      "\n",
      "\n",
      "16 :\n",
      "MSE:  4.581404108681745\n",
      "MAE:  0.7711433337744839\n",
      "acc:  0.9663173652694611\n",
      "Direct accuracy:  0.7717065868263473\n",
      "\n",
      "\n",
      "17 :\n",
      "MSE:  3.3044543018470627\n",
      "MAE:  0.659766216121034\n",
      "acc:  0.9745508982035929\n",
      "Direct accuracy:  0.781437125748503\n",
      "\n",
      "\n",
      "18 :\n",
      "MSE:  4.717517941724502\n",
      "MAE:  0.8248999897546754\n",
      "acc:  0.9625748502994012\n",
      "Direct accuracy:  0.7582335329341318\n",
      "\n",
      "\n",
      "19 :\n",
      "MSE:  4.127258801635982\n",
      "MAE:  0.7082120227644186\n",
      "acc:  0.967814371257485\n",
      "Direct accuracy:  0.7949101796407185\n",
      "\n",
      "\n",
      "20 :\n",
      "MSE:  4.236638697740437\n",
      "MAE:  0.7436998844325186\n",
      "acc:  0.968562874251497\n",
      "Direct accuracy:  0.7791916167664671\n",
      "\n",
      "\n",
      "21 :\n",
      "MSE:  3.3743715283647364\n",
      "MAE:  0.6704288688962331\n",
      "acc:  0.9715568862275449\n",
      "Direct accuracy:  0.7919161676646707\n",
      "\n",
      "\n",
      "22 :\n",
      "MSE:  3.798881329210417\n",
      "MAE:  0.6898021812879753\n",
      "acc:  0.9708083832335329\n",
      "Direct accuracy:  0.7866766467065869\n",
      "\n",
      "\n",
      "23 :\n",
      "MSE:  4.226901540136716\n",
      "MAE:  0.6883309287225415\n",
      "acc:  0.968562874251497\n",
      "Direct accuracy:  0.7926646706586826\n",
      "\n",
      "\n",
      "24 :\n",
      "MSE:  4.091972525131379\n",
      "MAE:  0.6761742565044743\n",
      "acc:  0.969311377245509\n",
      "Direct accuracy:  0.7904191616766467\n",
      "\n",
      "\n",
      "25 :\n",
      "MSE:  3.3730922605167777\n",
      "MAE:  0.66257127037573\n",
      "acc:  0.9715568862275449\n",
      "Direct accuracy:  0.7956586826347305\n",
      "\n",
      "\n",
      "26 :\n",
      "MSE:  4.921360831600639\n",
      "MAE:  0.7989696083802306\n",
      "acc:  0.9618263473053892\n",
      "Direct accuracy:  0.7634730538922155\n",
      "\n",
      "\n",
      "27 :\n",
      "MSE:  4.327974157505679\n",
      "MAE:  0.7913436752905746\n",
      "acc:  0.9670658682634731\n",
      "Direct accuracy:  0.7477544910179641\n",
      "\n",
      "\n",
      "28 :\n",
      "MSE:  4.617800873055023\n",
      "MAE:  0.7456765822887778\n",
      "acc:  0.9670658682634731\n",
      "Direct accuracy:  0.7866766467065869\n",
      "\n",
      "\n",
      "29 :\n",
      "MSE:  3.8459779782279324\n",
      "MAE:  0.696442719258948\n",
      "acc:  0.9700598802395209\n",
      "Direct accuracy:  0.7874251497005988\n",
      "\n",
      "\n",
      "30 :\n",
      "MSE:  3.761005913200058\n",
      "MAE:  0.6930300953859341\n",
      "acc:  0.9700598802395209\n",
      "Direct accuracy:  0.7754491017964071\n",
      "\n",
      "\n",
      "31 :\n",
      "MSE:  5.116781059795546\n",
      "MAE:  0.8208912501702765\n",
      "acc:  0.9595808383233533\n",
      "Direct accuracy:  0.7627245508982036\n",
      "\n",
      "\n",
      "32 :\n",
      "MSE:  2.255174510462431\n",
      "MAE:  0.5631339849603033\n",
      "acc:  0.9827844311377245\n",
      "Direct accuracy:  0.7926646706586826\n",
      "\n",
      "\n",
      "33 :\n",
      "MSE:  4.482513238102154\n",
      "MAE:  0.7331810383694971\n",
      "acc:  0.967814371257485\n",
      "Direct accuracy:  0.7829341317365269\n",
      "\n",
      "\n",
      "34 :\n",
      "MSE:  4.104295400109349\n",
      "MAE:  0.668751713535386\n",
      "acc:  0.967814371257485\n",
      "Direct accuracy:  0.8068862275449101\n",
      "\n",
      "\n",
      "35 :\n",
      "MSE:  3.38126131373275\n",
      "MAE:  0.6421936435212275\n",
      "acc:  0.9782934131736527\n",
      "Direct accuracy:  0.7851796407185628\n",
      "\n",
      "\n",
      "36 :\n",
      "MSE:  4.190950729748483\n",
      "MAE:  0.743729757200815\n",
      "acc:  0.967814371257485\n",
      "Direct accuracy:  0.7761976047904192\n",
      "\n",
      "\n",
      "37 :\n",
      "MSE:  4.1154314459525265\n",
      "MAE:  0.7027013228012773\n",
      "acc:  0.9670658682634731\n",
      "Direct accuracy:  0.7904191616766467\n",
      "\n",
      "\n",
      "38 :\n",
      "MSE:  4.097289827912073\n",
      "MAE:  0.7227580032707331\n",
      "acc:  0.967814371257485\n",
      "Direct accuracy:  0.782185628742515\n",
      "\n",
      "\n",
      "39 :\n",
      "MSE:  2.973821570564381\n",
      "MAE:  0.6277219187133684\n",
      "acc:  0.9745508982035929\n",
      "Direct accuracy:  0.7859281437125748\n",
      "\n",
      "\n",
      "40 :\n",
      "MSE:  3.6367637220829336\n",
      "MAE:  0.6368752005705219\n",
      "acc:  0.9738023952095809\n",
      "Direct accuracy:  0.7979041916167665\n",
      "\n",
      "\n",
      "41 :\n",
      "MSE:  3.587117615459798\n",
      "MAE:  0.6367847602033686\n",
      "acc:  0.9738023952095809\n",
      "Direct accuracy:  0.7904191616766467\n",
      "\n",
      "\n",
      "42 :\n",
      "MSE:  3.8213463265074328\n",
      "MAE:  0.6664909405667268\n",
      "acc:  0.9700598802395209\n",
      "Direct accuracy:  0.8061377245508982\n",
      "\n",
      "\n",
      "43 :\n",
      "MSE:  3.947536405665386\n",
      "MAE:  0.6938405034918628\n",
      "acc:  0.9708083832335329\n",
      "Direct accuracy:  0.7791916167664671\n",
      "\n",
      "\n",
      "44 :\n",
      "MSE:  3.9243403454992456\n",
      "MAE:  0.6855295999366009\n",
      "acc:  0.9738023952095809\n",
      "Direct accuracy:  0.7829341317365269\n",
      "\n",
      "\n",
      "45 :\n",
      "MSE:  3.9001592225188273\n",
      "MAE:  0.712874691152644\n",
      "acc:  0.968562874251497\n",
      "Direct accuracy:  0.7747005988023952\n",
      "\n",
      "\n",
      "46 :\n",
      "MSE:  3.7163494487663526\n",
      "MAE:  0.6953225328536805\n",
      "acc:  0.9670658682634731\n",
      "Direct accuracy:  0.7724550898203593\n",
      "\n",
      "\n",
      "47 :\n",
      "MSE:  4.329565817146446\n",
      "MAE:  0.754037232433786\n",
      "acc:  0.9670658682634731\n",
      "Direct accuracy:  0.7687125748502994\n",
      "\n",
      "\n",
      "48 :\n",
      "MSE:  3.0128154949503942\n",
      "MAE:  0.6177734856209355\n",
      "acc:  0.9775449101796407\n",
      "Direct accuracy:  0.8098802395209581\n",
      "\n",
      "\n",
      "49 :\n",
      "MSE:  3.604869593996663\n",
      "MAE:  0.6798899898049003\n",
      "acc:  0.9745508982035929\n",
      "Direct accuracy:  0.7784431137724551\n",
      "\n",
      "\n",
      "50 :\n",
      "MSE:  2.740049275270946\n",
      "MAE:  0.6317121910968584\n",
      "acc:  0.9805389221556886\n",
      "Direct accuracy:  0.7702095808383234\n",
      "\n",
      "\n",
      "51 :\n",
      "MSE:  4.343935358462166\n",
      "MAE:  0.6979284886783825\n",
      "acc:  0.968562874251497\n",
      "Direct accuracy:  0.7956586826347305\n",
      "\n",
      "\n",
      "52 :\n",
      "MSE:  3.942246508514983\n",
      "MAE:  0.7406874741399716\n",
      "acc:  0.9663173652694611\n",
      "Direct accuracy:  0.7642215568862275\n",
      "\n",
      "\n",
      "53 :\n",
      "MSE:  3.604390097365167\n",
      "MAE:  0.6940226471441948\n",
      "acc:  0.9708083832335329\n",
      "Direct accuracy:  0.7851796407185628\n",
      "\n",
      "\n",
      "54 :\n",
      "MSE:  3.1603125486701926\n",
      "MAE:  0.6194262645335612\n",
      "acc:  0.9760479041916168\n",
      "Direct accuracy:  0.7979041916167665\n",
      "\n",
      "\n",
      "55 :\n",
      "MSE:  3.9678235639462107\n",
      "MAE:  0.6901833961109916\n",
      "acc:  0.9715568862275449\n",
      "Direct accuracy:  0.7836826347305389\n",
      "\n",
      "\n",
      "56 :\n",
      "MSE:  4.1582876072835795\n",
      "MAE:  0.7068016576820505\n",
      "acc:  0.9700598802395209\n",
      "Direct accuracy:  0.7904191616766467\n",
      "\n",
      "\n",
      "57 :\n",
      "MSE:  3.415882250597126\n",
      "MAE:  0.6697292415547871\n",
      "acc:  0.9700598802395209\n",
      "Direct accuracy:  0.7881736526946108\n",
      "\n",
      "\n",
      "58 :\n",
      "MSE:  3.8851512459767523\n",
      "MAE:  0.7357677547428423\n",
      "acc:  0.9655688622754491\n",
      "Direct accuracy:  0.7544910179640718\n",
      "\n",
      "\n",
      "59 :\n",
      "MSE:  4.242680757981461\n",
      "MAE:  0.7017765342073883\n",
      "acc:  0.969311377245509\n",
      "Direct accuracy:  0.7889221556886228\n",
      "\n",
      "\n",
      "60 :\n",
      "MSE:  3.8427715830152662\n",
      "MAE:  0.7109985324347804\n",
      "acc:  0.968562874251497\n",
      "Direct accuracy:  0.780688622754491\n",
      "\n",
      "\n",
      "61 :\n",
      "MSE:  5.098512252842285\n",
      "MAE:  0.761147291182044\n",
      "acc:  0.9640718562874252\n",
      "Direct accuracy:  0.7851796407185628\n",
      "\n",
      "\n",
      "62 :\n",
      "MSE:  3.359990829249002\n",
      "MAE:  0.6807182318123872\n",
      "acc:  0.9738023952095809\n",
      "Direct accuracy:  0.7844311377245509\n",
      "\n",
      "\n",
      "63 :\n",
      "MSE:  3.893818883773322\n",
      "MAE:  0.6942907715673575\n",
      "acc:  0.9715568862275449\n",
      "Direct accuracy:  0.7829341317365269\n",
      "\n",
      "\n",
      "64 :\n",
      "MSE:  4.182206505061111\n",
      "MAE:  0.7386185680543949\n",
      "acc:  0.9655688622754491\n",
      "Direct accuracy:  0.7702095808383234\n",
      "\n",
      "\n",
      "65 :\n",
      "MSE:  4.49800900603925\n",
      "MAE:  0.7279087157841928\n",
      "acc:  0.969311377245509\n",
      "Direct accuracy:  0.7919161676646707\n",
      "\n",
      "\n",
      "66 :\n",
      "MSE:  4.149136931924419\n",
      "MAE:  0.7595089988303398\n",
      "acc:  0.9633233532934131\n",
      "Direct accuracy:  0.7732035928143712\n",
      "\n",
      "\n",
      "67 :\n",
      "MSE:  4.5110704003859015\n",
      "MAE:  0.7753609327186725\n",
      "acc:  0.9625748502994012\n",
      "Direct accuracy:  0.7747005988023952\n",
      "\n",
      "\n",
      "68 :\n",
      "MSE:  3.6502236330720286\n",
      "MAE:  0.647050765660887\n",
      "acc:  0.9723053892215568\n",
      "Direct accuracy:  0.7941616766467066\n",
      "\n",
      "\n",
      "69 :\n",
      "MSE:  3.6907283811337948\n",
      "MAE:  0.6695669529413035\n",
      "acc:  0.9715568862275449\n",
      "Direct accuracy:  0.7859281437125748\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 :\n",
      "MSE:  3.9765964625576564\n",
      "MAE:  0.7359300828176344\n",
      "acc:  0.968562874251497\n",
      "Direct accuracy:  0.7574850299401198\n",
      "\n",
      "\n",
      "71 :\n",
      "MSE:  3.360584587897115\n",
      "MAE:  0.6803445553262076\n",
      "acc:  0.9715568862275449\n",
      "Direct accuracy:  0.7881736526946108\n",
      "\n",
      "\n",
      "72 :\n",
      "MSE:  3.601505897390916\n",
      "MAE:  0.681953100074908\n",
      "acc:  0.9715568862275449\n",
      "Direct accuracy:  0.7799401197604791\n",
      "\n",
      "\n",
      "73 :\n",
      "MSE:  4.868352456713696\n",
      "MAE:  0.7642072109940523\n",
      "acc:  0.9670658682634731\n",
      "Direct accuracy:  0.7784431137724551\n",
      "\n",
      "\n",
      "74 :\n",
      "MSE:  4.370425721145578\n",
      "MAE:  0.7408607979779115\n",
      "acc:  0.9708083832335329\n",
      "Direct accuracy:  0.7791916167664671\n",
      "\n",
      "\n",
      "75 :\n",
      "MSE:  3.588220890553542\n",
      "MAE:  0.6798175316593961\n",
      "acc:  0.9738023952095809\n",
      "Direct accuracy:  0.7836826347305389\n",
      "\n",
      "\n",
      "76 :\n",
      "MSE:  4.8021510339212545\n",
      "MAE:  0.7844503418191108\n",
      "acc:  0.9618263473053892\n",
      "Direct accuracy:  0.7747005988023952\n",
      "\n",
      "\n",
      "77 :\n",
      "MSE:  4.044971513422575\n",
      "MAE:  0.7006519395344986\n",
      "acc:  0.9738023952095809\n",
      "Direct accuracy:  0.7896706586826348\n",
      "\n",
      "\n",
      "78 :\n",
      "MSE:  3.6573089385432382\n",
      "MAE:  0.6770641773849905\n",
      "acc:  0.9752994011976048\n",
      "Direct accuracy:  0.7776946107784432\n",
      "\n",
      "\n",
      "79 :\n",
      "MSE:  4.1732059789972595\n",
      "MAE:  0.7096080020917747\n",
      "acc:  0.9715568862275449\n",
      "Direct accuracy:  0.7724550898203593\n",
      "\n",
      "\n",
      "80 :\n",
      "MSE:  4.98148618322827\n",
      "MAE:  0.8104752793372748\n",
      "acc:  0.9603293413173652\n",
      "Direct accuracy:  0.7544910179640718\n",
      "\n",
      "\n",
      "81 :\n",
      "MSE:  3.4793517786275205\n",
      "MAE:  0.6773991341853213\n",
      "acc:  0.9752994011976048\n",
      "Direct accuracy:  0.7784431137724551\n",
      "\n",
      "\n",
      "82 :\n",
      "MSE:  5.323713517088267\n",
      "MAE:  0.8683790485792888\n",
      "acc:  0.9565868263473054\n",
      "Direct accuracy:  0.7537425149700598\n",
      "\n",
      "\n",
      "83 :\n",
      "MSE:  4.02955209585573\n",
      "MAE:  0.7454234365440772\n",
      "acc:  0.9700598802395209\n",
      "Direct accuracy:  0.7529940119760479\n",
      "\n",
      "\n",
      "84 :\n",
      "MSE:  4.194406026900515\n",
      "MAE:  0.7021028712659538\n",
      "acc:  0.9723053892215568\n",
      "Direct accuracy:  0.7949101796407185\n",
      "\n",
      "\n",
      "85 :\n",
      "MSE:  3.9029732179035457\n",
      "MAE:  0.6748004482534831\n",
      "acc:  0.9715568862275449\n",
      "Direct accuracy:  0.7881736526946108\n",
      "\n",
      "\n",
      "86 :\n",
      "MSE:  4.104072673234341\n",
      "MAE:  0.7654589538847258\n",
      "acc:  0.9655688622754491\n",
      "Direct accuracy:  0.7664670658682635\n",
      "\n",
      "\n",
      "87 :\n",
      "MSE:  4.356597366240399\n",
      "MAE:  0.7678865218635448\n",
      "acc:  0.969311377245509\n",
      "Direct accuracy:  0.7664670658682635\n",
      "\n",
      "\n",
      "88 :\n",
      "MSE:  3.975133407217053\n",
      "MAE:  0.7271607289548049\n",
      "acc:  0.967814371257485\n",
      "Direct accuracy:  0.7747005988023952\n",
      "\n",
      "\n",
      "89 :\n",
      "MSE:  4.347664540521448\n",
      "MAE:  0.7394234564400719\n",
      "acc:  0.969311377245509\n",
      "Direct accuracy:  0.7784431137724551\n",
      "\n",
      "\n",
      "90 :\n",
      "MSE:  3.849371171893298\n",
      "MAE:  0.707305979563626\n",
      "acc:  0.9723053892215568\n",
      "Direct accuracy:  0.7717065868263473\n",
      "\n",
      "\n",
      "91 :\n",
      "MSE:  3.9379428662983447\n",
      "MAE:  0.6914504465318012\n",
      "acc:  0.968562874251497\n",
      "Direct accuracy:  0.7979041916167665\n",
      "\n",
      "\n",
      "92 :\n",
      "MSE:  3.9065752902538646\n",
      "MAE:  0.6968378207373048\n",
      "acc:  0.9700598802395209\n",
      "Direct accuracy:  0.7791916167664671\n",
      "\n",
      "\n",
      "93 :\n",
      "MSE:  4.3171870459686925\n",
      "MAE:  0.7232498263572148\n",
      "acc:  0.9723053892215568\n",
      "Direct accuracy:  0.7776946107784432\n",
      "\n",
      "\n",
      "94 :\n",
      "MSE:  3.6569689781889334\n",
      "MAE:  0.6940393146060541\n",
      "acc:  0.9655688622754491\n",
      "Direct accuracy:  0.7844311377245509\n",
      "\n",
      "\n",
      "95 :\n",
      "MSE:  4.383546381677909\n",
      "MAE:  0.7552039274377024\n",
      "acc:  0.9655688622754491\n",
      "Direct accuracy:  0.7761976047904192\n",
      "\n",
      "\n",
      "96 :\n",
      "MSE:  3.8120886659701947\n",
      "MAE:  0.6886039496717339\n",
      "acc:  0.9723053892215568\n",
      "Direct accuracy:  0.7799401197604791\n",
      "\n",
      "\n",
      "97 :\n",
      "MSE:  4.763261188774009\n",
      "MAE:  0.766585863903611\n",
      "acc:  0.9595808383233533\n",
      "Direct accuracy:  0.7829341317365269\n",
      "\n",
      "\n",
      "98 :\n",
      "MSE:  4.353068164202809\n",
      "MAE:  0.757542039953663\n",
      "acc:  0.9663173652694611\n",
      "Direct accuracy:  0.780688622754491\n",
      "\n",
      "\n",
      "99 :\n",
      "MSE:  4.014978189432205\n",
      "MAE:  0.7093821921034488\n",
      "acc:  0.9708083832335329\n",
      "Direct accuracy:  0.7702095808383234\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "XGB_Acc = []\n",
    "\n",
    "for i in range(100):\n",
    "    X_train_16, X_test_16, y_train_16, y_test_16 = train_test_split( X_6v, y, test_size=0.2)\n",
    "\n",
    "    scaler=StandardScaler()\n",
    "    X_train_16=scaler.fit_transform(X_train_16)\n",
    "    X_test_16=scaler.transform(X_test_16)\n",
    "\n",
    "    XGB = XGBRegressor(n_jobs=-1,n_estimators=350,learning_rate=0.1,max_depth=8,gamma=0.2,colsample_bytree=0.6,objective='reg:squarederror')\n",
    "\n",
    "    XGB.fit(X_train_16,y_train_16)\n",
    "\n",
    "    # predict\n",
    "    y_pred_XGB = XGB.predict(X_test_16)\n",
    "    print(i, \":\")\n",
    "    print(\"MSE: \",mean_squared_error(y_test_16, y_pred_XGB))\n",
    "    print(\"MAE: \", mean_absolute_error(y_test_16, y_pred_XGB))\n",
    "\n",
    "    # round\n",
    "    y_1_XGB = np.around(y_pred_XGB)\n",
    "    y_1_XGB = y_1_XGB.astype(int)\n",
    "\n",
    "    # difference between prediction and label\n",
    "    diff_XGB = abs(y_1_XGB-y_test_16)\n",
    "\n",
    "    # <=5 then 0\n",
    "    round_diff_XGB = np.zeros(len(y_test_16))\n",
    "    for i in range(len(y_test_16)):\n",
    "        if abs(y_1_XGB[i]-y_test_16[i])<=5:\n",
    "            round_diff_XGB[i] = 0\n",
    "        else:\n",
    "            round_diff_XGB[i] = abs(y_1_XGB[i]-y_test_16[i])\n",
    "\n",
    "    # +- 5 pixels are regarded as correctly-classified\n",
    "    acc_XGB = 1-np.count_nonzero(round_diff_XGB)/len(y_test_16)\n",
    "    print(\"acc: \", acc_XGB)\n",
    "    # direct accuracy\n",
    "    print(\"Direct accuracy: \",(len(diff_XGB) - np.count_nonzero(diff_XGB))/len(diff_XGB))\n",
    "    print(\"\\n\")\n",
    "    XGB_Acc.append(acc_XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9695359281437125\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(XGB_Acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ±3pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :\n",
      "MSE:  3.596968083302414\n",
      "MAE:  0.661938481322841\n",
      "acc:  0.9491017964071856\n",
      "Direct accuracy:  0.7769461077844312\n",
      "\n",
      "\n",
      "1 :\n",
      "MSE:  4.796442016449819\n",
      "MAE:  0.7963961589033018\n",
      "acc:  0.936377245508982\n",
      "Direct accuracy:  0.7537425149700598\n",
      "\n",
      "\n",
      "2 :\n",
      "MSE:  4.192269889542058\n",
      "MAE:  0.7018411767161535\n",
      "acc:  0.9453592814371258\n",
      "Direct accuracy:  0.7859281437125748\n",
      "\n",
      "\n",
      "3 :\n",
      "MSE:  3.571732345650219\n",
      "MAE:  0.6728908124485773\n",
      "acc:  0.9476047904191617\n",
      "Direct accuracy:  0.781437125748503\n",
      "\n",
      "\n",
      "4 :\n",
      "MSE:  3.9755630379622753\n",
      "MAE:  0.7188827517236064\n",
      "acc:  0.937874251497006\n",
      "Direct accuracy:  0.7829341317365269\n",
      "\n",
      "\n",
      "5 :\n",
      "MSE:  3.361743463765259\n",
      "MAE:  0.6699398731489381\n",
      "acc:  0.9461077844311377\n",
      "Direct accuracy:  0.7851796407185628\n",
      "\n",
      "\n",
      "6 :\n",
      "MSE:  3.810950176375208\n",
      "MAE:  0.6649120877647471\n",
      "acc:  0.9543413173652695\n",
      "Direct accuracy:  0.7851796407185628\n",
      "\n",
      "\n",
      "7 :\n",
      "MSE:  3.588542653017267\n",
      "MAE:  0.6610694509334193\n",
      "acc:  0.9513473053892215\n",
      "Direct accuracy:  0.7971556886227545\n",
      "\n",
      "\n",
      "8 :\n",
      "MSE:  3.862304932358673\n",
      "MAE:  0.6942203294954257\n",
      "acc:  0.9446107784431138\n",
      "Direct accuracy:  0.7866766467065869\n",
      "\n",
      "\n",
      "9 :\n",
      "MSE:  4.694022082384717\n",
      "MAE:  0.7628808512302216\n",
      "acc:  0.9453592814371258\n",
      "Direct accuracy:  0.7687125748502994\n",
      "\n",
      "\n",
      "10 :\n",
      "MSE:  3.964717081810008\n",
      "MAE:  0.7423206369230847\n",
      "acc:  0.9356287425149701\n",
      "Direct accuracy:  0.7732035928143712\n",
      "\n",
      "\n",
      "11 :\n",
      "MSE:  3.5368878989397046\n",
      "MAE:  0.7001078999238813\n",
      "acc:  0.9468562874251497\n",
      "Direct accuracy:  0.7761976047904192\n",
      "\n",
      "\n",
      "12 :\n",
      "MSE:  3.6221415613611043\n",
      "MAE:  0.7144113279611408\n",
      "acc:  0.936377245508982\n",
      "Direct accuracy:  0.7866766467065869\n",
      "\n",
      "\n",
      "13 :\n",
      "MSE:  4.354578793146782\n",
      "MAE:  0.7110217829753539\n",
      "acc:  0.9513473053892215\n",
      "Direct accuracy:  0.7874251497005988\n",
      "\n",
      "\n",
      "14 :\n",
      "MSE:  4.419818443680302\n",
      "MAE:  0.7690022897622185\n",
      "acc:  0.9341317365269461\n",
      "Direct accuracy:  0.7747005988023952\n",
      "\n",
      "\n",
      "15 :\n",
      "MSE:  3.8692433353985685\n",
      "MAE:  0.6970413345285875\n",
      "acc:  0.9491017964071856\n",
      "Direct accuracy:  0.7754491017964071\n",
      "\n",
      "\n",
      "16 :\n",
      "MSE:  3.8561876420079084\n",
      "MAE:  0.7146656266051138\n",
      "acc:  0.9438622754491018\n",
      "Direct accuracy:  0.7687125748502994\n",
      "\n",
      "\n",
      "17 :\n",
      "MSE:  4.17285407870737\n",
      "MAE:  0.696363364485745\n",
      "acc:  0.9468562874251497\n",
      "Direct accuracy:  0.7881736526946108\n",
      "\n",
      "\n",
      "18 :\n",
      "MSE:  2.351827230037962\n",
      "MAE:  0.5368340158623136\n",
      "acc:  0.9655688622754491\n",
      "Direct accuracy:  0.7964071856287425\n",
      "\n",
      "\n",
      "19 :\n",
      "MSE:  4.331767782524285\n",
      "MAE:  0.7071886989483219\n",
      "acc:  0.9461077844311377\n",
      "Direct accuracy:  0.7866766467065869\n",
      "\n",
      "\n",
      "20 :\n",
      "MSE:  3.6104557165018103\n",
      "MAE:  0.6626057730329608\n",
      "acc:  0.9543413173652695\n",
      "Direct accuracy:  0.7911676646706587\n",
      "\n",
      "\n",
      "21 :\n",
      "MSE:  3.296401106484323\n",
      "MAE:  0.639504357882424\n",
      "acc:  0.9558383233532934\n",
      "Direct accuracy:  0.7919161676646707\n",
      "\n",
      "\n",
      "22 :\n",
      "MSE:  3.898589552942034\n",
      "MAE:  0.707999406036681\n",
      "acc:  0.9491017964071856\n",
      "Direct accuracy:  0.7776946107784432\n",
      "\n",
      "\n",
      "23 :\n",
      "MSE:  3.8126786334101457\n",
      "MAE:  0.6939689198252327\n",
      "acc:  0.9520958083832335\n",
      "Direct accuracy:  0.7702095808383234\n",
      "\n",
      "\n",
      "24 :\n",
      "MSE:  4.822864741603721\n",
      "MAE:  0.7867804733802102\n",
      "acc:  0.936377245508982\n",
      "Direct accuracy:  0.7634730538922155\n",
      "\n",
      "\n",
      "25 :\n",
      "MSE:  5.173122715917805\n",
      "MAE:  0.8182341164859113\n",
      "acc:  0.937125748502994\n",
      "Direct accuracy:  0.7634730538922155\n",
      "\n",
      "\n",
      "26 :\n",
      "MSE:  3.0633233455735414\n",
      "MAE:  0.6481767293445008\n",
      "acc:  0.9505988023952096\n",
      "Direct accuracy:  0.7761976047904192\n",
      "\n",
      "\n",
      "27 :\n",
      "MSE:  3.0935682857594715\n",
      "MAE:  0.6507185895865906\n",
      "acc:  0.9505988023952096\n",
      "Direct accuracy:  0.7784431137724551\n",
      "\n",
      "\n",
      "28 :\n",
      "MSE:  5.7640384521813335\n",
      "MAE:  0.856694752339296\n",
      "acc:  0.9401197604790419\n",
      "Direct accuracy:  0.7544910179640718\n",
      "\n",
      "\n",
      "29 :\n",
      "MSE:  3.342723816827007\n",
      "MAE:  0.6373217840216117\n",
      "acc:  0.9565868263473054\n",
      "Direct accuracy:  0.7836826347305389\n",
      "\n",
      "\n",
      "30 :\n",
      "MSE:  4.183373175656824\n",
      "MAE:  0.6861812143982527\n",
      "acc:  0.9558383233532934\n",
      "Direct accuracy:  0.7889221556886228\n",
      "\n",
      "\n",
      "31 :\n",
      "MSE:  3.742782475723995\n",
      "MAE:  0.7118983923451986\n",
      "acc:  0.9453592814371258\n",
      "Direct accuracy:  0.7679640718562875\n",
      "\n",
      "\n",
      "32 :\n",
      "MSE:  5.004726049144174\n",
      "MAE:  0.8103795759826006\n",
      "acc:  0.9348802395209581\n",
      "Direct accuracy:  0.7657185628742516\n",
      "\n",
      "\n",
      "33 :\n",
      "MSE:  4.4066581314549955\n",
      "MAE:  0.7668224305672917\n",
      "acc:  0.9416167664670658\n",
      "Direct accuracy:  0.7627245508982036\n",
      "\n",
      "\n",
      "34 :\n",
      "MSE:  3.587823528728206\n",
      "MAE:  0.7219341215259301\n",
      "acc:  0.9453592814371258\n",
      "Direct accuracy:  0.7664670658682635\n",
      "\n",
      "\n",
      "35 :\n",
      "MSE:  3.513219752455568\n",
      "MAE:  0.6630923781923191\n",
      "acc:  0.9453592814371258\n",
      "Direct accuracy:  0.7844311377245509\n",
      "\n",
      "\n",
      "36 :\n",
      "MSE:  4.224604668144461\n",
      "MAE:  0.7463823724649623\n",
      "acc:  0.9341317365269461\n",
      "Direct accuracy:  0.7739520958083832\n",
      "\n",
      "\n",
      "37 :\n",
      "MSE:  3.000796445295532\n",
      "MAE:  0.6539946113919427\n",
      "acc:  0.9468562874251497\n",
      "Direct accuracy:  0.7799401197604791\n",
      "\n",
      "\n",
      "38 :\n",
      "MSE:  3.7467927640045455\n",
      "MAE:  0.6488494535540036\n",
      "acc:  0.9595808383233533\n",
      "Direct accuracy:  0.7874251497005988\n",
      "\n",
      "\n",
      "39 :\n",
      "MSE:  3.870302393540333\n",
      "MAE:  0.6872855917422357\n",
      "acc:  0.9528443113772456\n",
      "Direct accuracy:  0.7717065868263473\n",
      "\n",
      "\n",
      "40 :\n",
      "MSE:  4.280544536200574\n",
      "MAE:  0.7744420748984743\n",
      "acc:  0.937125748502994\n",
      "Direct accuracy:  0.7559880239520959\n",
      "\n",
      "\n",
      "41 :\n",
      "MSE:  2.6562239404636956\n",
      "MAE:  0.6246371962531598\n",
      "acc:  0.9505988023952096\n",
      "Direct accuracy:  0.782185628742515\n",
      "\n",
      "\n",
      "42 :\n",
      "MSE:  4.064989151201237\n",
      "MAE:  0.7448906204746869\n",
      "acc:  0.937874251497006\n",
      "Direct accuracy:  0.7694610778443114\n",
      "\n",
      "\n",
      "43 :\n",
      "MSE:  4.316502895867967\n",
      "MAE:  0.7325400010777448\n",
      "acc:  0.9408682634730539\n",
      "Direct accuracy:  0.7776946107784432\n",
      "\n",
      "\n",
      "44 :\n",
      "MSE:  3.788083603685179\n",
      "MAE:  0.7029682835062107\n",
      "acc:  0.9453592814371258\n",
      "Direct accuracy:  0.7679640718562875\n",
      "\n",
      "\n",
      "45 :\n",
      "MSE:  2.9967234362758384\n",
      "MAE:  0.6365805751683112\n",
      "acc:  0.9498502994011976\n",
      "Direct accuracy:  0.7844311377245509\n",
      "\n",
      "\n",
      "46 :\n",
      "MSE:  4.6822789658\n",
      "MAE:  0.7564415100984231\n",
      "acc:  0.9438622754491018\n",
      "Direct accuracy:  0.7694610778443114\n",
      "\n",
      "\n",
      "47 :\n",
      "MSE:  3.4697146144919335\n",
      "MAE:  0.6612388027196159\n",
      "acc:  0.9476047904191617\n",
      "Direct accuracy:  0.780688622754491\n",
      "\n",
      "\n",
      "48 :\n",
      "MSE:  3.7731357027013948\n",
      "MAE:  0.7125430584266157\n",
      "acc:  0.9408682634730539\n",
      "Direct accuracy:  0.781437125748503\n",
      "\n",
      "\n",
      "49 :\n",
      "MSE:  4.162519082725207\n",
      "MAE:  0.7376665240097903\n",
      "acc:  0.9341317365269461\n",
      "Direct accuracy:  0.7844311377245509\n",
      "\n",
      "\n",
      "50 :\n",
      "MSE:  3.9370866698131746\n",
      "MAE:  0.7049130908698736\n",
      "acc:  0.9505988023952096\n",
      "Direct accuracy:  0.7747005988023952\n",
      "\n",
      "\n",
      "51 :\n",
      "MSE:  4.402843632933214\n",
      "MAE:  0.7468161340691373\n",
      "acc:  0.9483532934131736\n",
      "Direct accuracy:  0.7679640718562875\n",
      "\n",
      "\n",
      "52 :\n",
      "MSE:  4.224855686308936\n",
      "MAE:  0.7327740525012602\n",
      "acc:  0.937874251497006\n",
      "Direct accuracy:  0.7769461077844312\n",
      "\n",
      "\n",
      "53 :\n",
      "MSE:  3.9988121586857717\n",
      "MAE:  0.7311876179304665\n",
      "acc:  0.9408682634730539\n",
      "Direct accuracy:  0.7679640718562875\n",
      "\n",
      "\n",
      "54 :\n",
      "MSE:  3.7791199377312283\n",
      "MAE:  0.6809039056791873\n",
      "acc:  0.9438622754491018\n",
      "Direct accuracy:  0.7926646706586826\n",
      "\n",
      "\n",
      "55 :\n",
      "MSE:  5.039579752440422\n",
      "MAE:  0.7944173733006694\n",
      "acc:  0.937874251497006\n",
      "Direct accuracy:  0.7709580838323353\n",
      "\n",
      "\n",
      "56 :\n",
      "MSE:  3.945814407625646\n",
      "MAE:  0.711143592339076\n",
      "acc:  0.9401197604790419\n",
      "Direct accuracy:  0.7836826347305389\n",
      "\n",
      "\n",
      "57 :\n",
      "MSE:  3.40362477323721\n",
      "MAE:  0.6663188518967457\n",
      "acc:  0.9468562874251497\n",
      "Direct accuracy:  0.7904191616766467\n",
      "\n",
      "\n",
      "58 :\n",
      "MSE:  3.3284171273241396\n",
      "MAE:  0.6569833206291684\n",
      "acc:  0.9461077844311377\n",
      "Direct accuracy:  0.7926646706586826\n",
      "\n",
      "\n",
      "59 :\n",
      "MSE:  3.3860221476487466\n",
      "MAE:  0.6586874518878089\n",
      "acc:  0.9543413173652695\n",
      "Direct accuracy:  0.7717065868263473\n",
      "\n",
      "\n",
      "60 :\n",
      "MSE:  4.3692527111697155\n",
      "MAE:  0.7670977279588491\n",
      "acc:  0.9326347305389222\n",
      "Direct accuracy:  0.7642215568862275\n",
      "\n",
      "\n",
      "61 :\n",
      "MSE:  3.0615336870640126\n",
      "MAE:  0.6478364601686686\n",
      "acc:  0.9520958083832335\n",
      "Direct accuracy:  0.7717065868263473\n",
      "\n",
      "\n",
      "62 :\n",
      "MSE:  2.932442010005924\n",
      "MAE:  0.6360541166525758\n",
      "acc:  0.9573353293413174\n",
      "Direct accuracy:  0.7754491017964071\n",
      "\n",
      "\n",
      "63 :\n",
      "MSE:  3.759505811843038\n",
      "MAE:  0.7011557925425603\n",
      "acc:  0.9416167664670658\n",
      "Direct accuracy:  0.7776946107784432\n",
      "\n",
      "\n",
      "64 :\n",
      "MSE:  4.167348707541111\n",
      "MAE:  0.7085495903686492\n",
      "acc:  0.9453592814371258\n",
      "Direct accuracy:  0.781437125748503\n",
      "\n",
      "\n",
      "65 :\n",
      "MSE:  3.099402295794171\n",
      "MAE:  0.621539683711386\n",
      "acc:  0.9580838323353293\n",
      "Direct accuracy:  0.7874251497005988\n",
      "\n",
      "\n",
      "66 :\n",
      "MSE:  3.623605881777101\n",
      "MAE:  0.6504664225001892\n",
      "acc:  0.9491017964071856\n",
      "Direct accuracy:  0.8046407185628742\n",
      "\n",
      "\n",
      "67 :\n",
      "MSE:  4.143289882619121\n",
      "MAE:  0.7492496659923457\n",
      "acc:  0.9408682634730539\n",
      "Direct accuracy:  0.7657185628742516\n",
      "\n",
      "\n",
      "68 :\n",
      "MSE:  4.2735895227881455\n",
      "MAE:  0.739682150547376\n",
      "acc:  0.9431137724550899\n",
      "Direct accuracy:  0.7732035928143712\n",
      "\n",
      "\n",
      "69 :\n",
      "MSE:  3.6531928532104665\n",
      "MAE:  0.6594797013450169\n",
      "acc:  0.9543413173652695\n",
      "Direct accuracy:  0.7881736526946108\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 :\n",
      "MSE:  4.435489989311765\n",
      "MAE:  0.7670726794861034\n",
      "acc:  0.9333832335329342\n",
      "Direct accuracy:  0.7709580838323353\n",
      "\n",
      "\n",
      "71 :\n",
      "MSE:  3.9869222765723227\n",
      "MAE:  0.6872839991694796\n",
      "acc:  0.9498502994011976\n",
      "Direct accuracy:  0.782185628742515\n",
      "\n",
      "\n",
      "72 :\n",
      "MSE:  3.752848800164899\n",
      "MAE:  0.6601914252617402\n",
      "acc:  0.9505988023952096\n",
      "Direct accuracy:  0.8053892215568862\n",
      "\n",
      "\n",
      "73 :\n",
      "MSE:  4.155923212245406\n",
      "MAE:  0.7573855212348664\n",
      "acc:  0.9356287425149701\n",
      "Direct accuracy:  0.7642215568862275\n",
      "\n",
      "\n",
      "74 :\n",
      "MSE:  3.9514141054003966\n",
      "MAE:  0.7356585993649003\n",
      "acc:  0.9416167664670658\n",
      "Direct accuracy:  0.7604790419161677\n",
      "\n",
      "\n",
      "75 :\n",
      "MSE:  4.196699263156397\n",
      "MAE:  0.7266277211556534\n",
      "acc:  0.9416167664670658\n",
      "Direct accuracy:  0.7904191616766467\n",
      "\n",
      "\n",
      "76 :\n",
      "MSE:  3.739518616289651\n",
      "MAE:  0.689335030531455\n",
      "acc:  0.9468562874251497\n",
      "Direct accuracy:  0.7761976047904192\n",
      "\n",
      "\n",
      "77 :\n",
      "MSE:  5.025672957651618\n",
      "MAE:  0.7790948619653365\n",
      "acc:  0.9453592814371258\n",
      "Direct accuracy:  0.7761976047904192\n",
      "\n",
      "\n",
      "78 :\n",
      "MSE:  4.956346108538337\n",
      "MAE:  0.8157040248820168\n",
      "acc:  0.9333832335329342\n",
      "Direct accuracy:  0.7672155688622755\n",
      "\n",
      "\n",
      "79 :\n",
      "MSE:  4.150438789783094\n",
      "MAE:  0.7110395467209959\n",
      "acc:  0.9401197604790419\n",
      "Direct accuracy:  0.7784431137724551\n",
      "\n",
      "\n",
      "80 :\n",
      "MSE:  3.6433340130755996\n",
      "MAE:  0.7188148737890635\n",
      "acc:  0.9513473053892215\n",
      "Direct accuracy:  0.7559880239520959\n",
      "\n",
      "\n",
      "81 :\n",
      "MSE:  3.7023397921305774\n",
      "MAE:  0.7061783254681947\n",
      "acc:  0.9446107784431138\n",
      "Direct accuracy:  0.7739520958083832\n",
      "\n",
      "\n",
      "82 :\n",
      "MSE:  4.56282021102106\n",
      "MAE:  0.7714126167852364\n",
      "acc:  0.9393712574850299\n",
      "Direct accuracy:  0.7709580838323353\n",
      "\n",
      "\n",
      "83 :\n",
      "MSE:  4.188928179778104\n",
      "MAE:  0.7757811451297321\n",
      "acc:  0.9333832335329342\n",
      "Direct accuracy:  0.7597305389221557\n",
      "\n",
      "\n",
      "84 :\n",
      "MSE:  5.022097478675698\n",
      "MAE:  0.7715844221993121\n",
      "acc:  0.9446107784431138\n",
      "Direct accuracy:  0.7881736526946108\n",
      "\n",
      "\n",
      "85 :\n",
      "MSE:  3.910843625763937\n",
      "MAE:  0.6817237689288077\n",
      "acc:  0.9520958083832335\n",
      "Direct accuracy:  0.7889221556886228\n",
      "\n",
      "\n",
      "86 :\n",
      "MSE:  4.245364404804533\n",
      "MAE:  0.7832898324478172\n",
      "acc:  0.9401197604790419\n",
      "Direct accuracy:  0.7514970059880239\n",
      "\n",
      "\n",
      "87 :\n",
      "MSE:  4.536029019911508\n",
      "MAE:  0.7845627169632269\n",
      "acc:  0.9408682634730539\n",
      "Direct accuracy:  0.7582335329341318\n",
      "\n",
      "\n",
      "88 :\n",
      "MSE:  3.9433003926909307\n",
      "MAE:  0.7168693226388472\n",
      "acc:  0.9483532934131736\n",
      "Direct accuracy:  0.7732035928143712\n",
      "\n",
      "\n",
      "89 :\n",
      "MSE:  4.2603141313110795\n",
      "MAE:  0.7244369317582268\n",
      "acc:  0.9461077844311377\n",
      "Direct accuracy:  0.7859281437125748\n",
      "\n",
      "\n",
      "90 :\n",
      "MSE:  3.4077843896352316\n",
      "MAE:  0.6770061288854319\n",
      "acc:  0.9505988023952096\n",
      "Direct accuracy:  0.7836826347305389\n",
      "\n",
      "\n",
      "91 :\n",
      "MSE:  3.2427400966277173\n",
      "MAE:  0.6773454051933245\n",
      "acc:  0.9535928143712575\n",
      "Direct accuracy:  0.7679640718562875\n",
      "\n",
      "\n",
      "92 :\n",
      "MSE:  3.2804139157587935\n",
      "MAE:  0.6047531238974568\n",
      "acc:  0.9625748502994012\n",
      "Direct accuracy:  0.7949101796407185\n",
      "\n",
      "\n",
      "93 :\n",
      "MSE:  3.9324240012012637\n",
      "MAE:  0.7011059465076395\n",
      "acc:  0.9431137724550899\n",
      "Direct accuracy:  0.7896706586826348\n",
      "\n",
      "\n",
      "94 :\n",
      "MSE:  3.6094418273683555\n",
      "MAE:  0.7245411745490071\n",
      "acc:  0.9423652694610778\n",
      "Direct accuracy:  0.7642215568862275\n",
      "\n",
      "\n",
      "95 :\n",
      "MSE:  3.534926348775342\n",
      "MAE:  0.7018812011458917\n",
      "acc:  0.9431137724550899\n",
      "Direct accuracy:  0.7761976047904192\n",
      "\n",
      "\n",
      "96 :\n",
      "MSE:  4.394639135330944\n",
      "MAE:  0.7611934465919427\n",
      "acc:  0.9393712574850299\n",
      "Direct accuracy:  0.7724550898203593\n",
      "\n",
      "\n",
      "97 :\n",
      "MSE:  3.3707690753667574\n",
      "MAE:  0.6948450709620636\n",
      "acc:  0.9446107784431138\n",
      "Direct accuracy:  0.7732035928143712\n",
      "\n",
      "\n",
      "98 :\n",
      "MSE:  3.731178285818027\n",
      "MAE:  0.7150883364106366\n",
      "acc:  0.9348802395209581\n",
      "Direct accuracy:  0.7791916167664671\n",
      "\n",
      "\n",
      "99 :\n",
      "MSE:  4.686198273409356\n",
      "MAE:  0.7541275509147943\n",
      "acc:  0.9461077844311377\n",
      "Direct accuracy:  0.780688622754491\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "XGB_Acc = []\n",
    "\n",
    "for i in range(100):\n",
    "    X_train_16, X_test_16, y_train_16, y_test_16 = train_test_split( X_6v, y, test_size=0.2)\n",
    "\n",
    "    scaler=StandardScaler()\n",
    "    X_train_16=scaler.fit_transform(X_train_16)\n",
    "    X_test_16=scaler.transform(X_test_16)\n",
    "\n",
    "    XGB = XGBRegressor(n_jobs=-1,n_estimators=350,learning_rate=0.1,max_depth=8,gamma=0.2,colsample_bytree=0.6,objective='reg:squarederror')\n",
    "\n",
    "    XGB.fit(X_train_16,y_train_16)\n",
    "\n",
    "    # predict\n",
    "    y_pred_XGB = XGB.predict(X_test_16)\n",
    "    print(i, \":\")\n",
    "    print(\"MSE: \",mean_squared_error(y_test_16, y_pred_XGB))\n",
    "    print(\"MAE: \", mean_absolute_error(y_test_16, y_pred_XGB))\n",
    "\n",
    "    # round\n",
    "    y_1_XGB = np.around(y_pred_XGB)\n",
    "    y_1_XGB = y_1_XGB.astype(int)\n",
    "\n",
    "    # difference between prediction and label\n",
    "    diff_XGB = abs(y_1_XGB-y_test_16)\n",
    "\n",
    "    # <=3 then 0\n",
    "    round_diff_XGB = np.zeros(len(y_test_16))\n",
    "    for i in range(len(y_test_16)):\n",
    "        if abs(y_1_XGB[i]-y_test_16[i])<=3:\n",
    "            round_diff_XGB[i] = 0\n",
    "        else:\n",
    "            round_diff_XGB[i] = abs(y_1_XGB[i]-y_test_16[i])\n",
    "\n",
    "    # +- 3 pixels are regarded as correctly-classified\n",
    "    acc_XGB = 1-np.count_nonzero(round_diff_XGB)/len(y_test_16)\n",
    "    print(\"acc: \", acc_XGB)\n",
    "    # direct accuracy\n",
    "    print(\"Direct accuracy: \",(len(diff_XGB) - np.count_nonzero(diff_XGB))/len(diff_XGB))\n",
    "    print(\"\\n\")\n",
    "    XGB_Acc.append(acc_XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9452769461077846\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(XGB_Acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "Best parameters: {'num_leaves': 32, 'n_estimators': 350, 'min_child_samples': 8, 'max_depth': 20, 'learning_rate': 0.1}\n",
      "MSE: 4.1805\n",
      "MAE: 0.7490\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "Round 2\n",
      "Best parameters: {'num_leaves': 48, 'n_estimators': 350, 'min_child_samples': 32, 'max_depth': 20, 'learning_rate': 0.1}\n",
      "MSE: 3.9863\n",
      "MAE: 0.7708\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "Round 3\n",
      "Best parameters: {'num_leaves': 48, 'n_estimators': 300, 'min_child_samples': 8, 'max_depth': 20, 'learning_rate': 0.1}\n",
      "MSE: 4.2792\n",
      "MAE: 0.7192\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "Round 4\n",
      "Best parameters: {'num_leaves': 32, 'n_estimators': 350, 'min_child_samples': 8, 'max_depth': 8, 'learning_rate': 0.03}\n",
      "MSE: 4.1312\n",
      "MAE: 0.9675\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "Round 5\n",
      "Best parameters: {'num_leaves': 32, 'n_estimators': 350, 'min_child_samples': 8, 'max_depth': 20, 'learning_rate': 0.03}\n",
      "MSE: 5.2857\n",
      "MAE: 1.0302\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "Round 6\n",
      "Best parameters: {'num_leaves': 32, 'n_estimators': 300, 'min_child_samples': 24, 'max_depth': 16, 'learning_rate': 0.1}\n",
      "MSE: 3.8136\n",
      "MAE: 0.7981\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "Round 7\n",
      "Best parameters: {'num_leaves': 32, 'n_estimators': 250, 'min_child_samples': 8, 'max_depth': 24, 'learning_rate': 0.1}\n",
      "MSE: 3.6550\n",
      "MAE: 0.7604\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "Round 8\n",
      "Best parameters: {'num_leaves': 24, 'n_estimators': 350, 'min_child_samples': 20, 'max_depth': 8, 'learning_rate': 0.1}\n",
      "MSE: 3.5296\n",
      "MAE: 0.8126\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "Round 9\n",
      "Best parameters: {'num_leaves': 16, 'n_estimators': 350, 'min_child_samples': 8, 'max_depth': 24, 'learning_rate': 0.1}\n",
      "MSE: 3.7491\n",
      "MAE: 0.8833\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "Round 10\n",
      "Best parameters: {'num_leaves': 24, 'n_estimators': 250, 'min_child_samples': 20, 'max_depth': 32, 'learning_rate': 0.1}\n",
      "MSE: 3.4617\n",
      "MAE: 0.8433\n",
      "----------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ave_score_LGB_MSE_final = []\n",
    "ave_score_LGB_MAE_final = []\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "  X_train_16, X_test_16, y_train_16, y_test_16 = train_test_split( X_6v, y, test_size=0.2)\n",
    "\n",
    "  scaler=StandardScaler()\n",
    "  X_train_16=scaler.fit_transform(X_train_16)\n",
    "  X_test_16=scaler.transform(X_test_16)\n",
    "\n",
    "  LGB = LGBMRegressor(n_jobs=-1,colsample_bytree=0.6)\n",
    "\n",
    "  param_grid = {\n",
    "          \"n_estimators\": [250,300,350],\n",
    "          \"learning_rate\": [0.01, 0.03, 0.10],\n",
    "          \"num_leaves\": [16,24,32,40,48],\n",
    "          \"max_depth\": [8,16,20,24,32],\n",
    "          \"min_child_samples\": [8,16,20,24,32]\n",
    "          }\n",
    "  LGB_grid = RandomizedSearchCV(LGB, param_grid, cv=5)\n",
    "  LGB_grid.fit(X_train_16,y_train_16)\n",
    "  best_est_LGB = LGB_grid.best_estimator_ \n",
    "\n",
    "  best_est_LGB.fit(X_train_16,y_train_16)\n",
    "\n",
    "  y_pred = best_est_LGB.predict(X_test_16)\n",
    "  print('Round {}'.format(i+1))\n",
    "  print('Best parameters:', LGB_grid.best_params_)\n",
    "  print('MSE: {:.4f}'.format(mean_squared_error(y_test_16, y_pred)))\n",
    "  print('MAE: {:.4f}'.format(mean_absolute_error(y_test_16, y_pred)))\n",
    "\n",
    "  print('----------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "  ave_score_LGB_MSE_final.append(mean_squared_error(y_test_16, y_pred))\n",
    "  ave_score_LGB_MAE_final.append(mean_absolute_error(y_test_16, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MSE: 4.007201722622896\n",
      "average MAE: 0.8334229056294271\n"
     ]
    }
   ],
   "source": [
    "print(\"average MSE: {}\".format(np.mean(ave_score_LGB_MSE_final)))\n",
    "print(\"average MAE: {}\".format(np.mean(ave_score_LGB_MAE_final)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### num_leaves=32\n",
    "### n_estimators=350\n",
    "### learning_rate=0.1\n",
    "### min_child_samples=8\n",
    "### max_depth=20\n",
    "### colsample_bytree=0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  3.722438766705641\n",
      "MAE:  0.7163124487401377\n"
     ]
    }
   ],
   "source": [
    "MSE = []\n",
    "MAE = []\n",
    "for i in range(10):\n",
    "    X_train_16, X_test_16, y_train_16, y_test_16 = train_test_split( X_6v, y, test_size=0.2)\n",
    "\n",
    "    scaler=StandardScaler()\n",
    "    X_train_16=scaler.fit_transform(X_train_16)\n",
    "    X_test_16=scaler.transform(X_test_16)\n",
    "\n",
    "    LGB = LGBMRegressor(n_jobs=-1,num_leaves=32,n_estimators=350,learning_rate=0.1,min_child_samples=8,max_depth=20,colsample_bytree=0.6)\n",
    "\n",
    "    LGB.fit(X_train_16,y_train_16)\n",
    "    \n",
    "    y_pred = LGB.predict(X_test_16)\n",
    "    \n",
    "    MSE.append(mean_squared_error(y_test_16, y_pred))\n",
    "    MAE.append(mean_absolute_error(y_test_16, y_pred))\n",
    "\n",
    "print(\"MSE: \", np.mean(MSE))\n",
    "print(\"MAE: \", np.mean(MAE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  1.9293622694314412\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print(\"RMSE: \", math.sqrt(np.mean(MSE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formal test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(colsample_bytree=0.6, max_depth=16, min_child_samples=8,\n",
       "              n_estimators=350, num_leaves=32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_16, X_test_16, y_train_16, y_test_16 = train_test_split( X_6v, y, test_size=0.2)\n",
    "\n",
    "scaler=StandardScaler()\n",
    "X_train_16=scaler.fit_transform(X_train_16)\n",
    "X_test_16=scaler.transform(X_test_16)\n",
    "\n",
    "# max_depth=20\n",
    "LGB = LGBMRegressor(n_jobs=-1,num_leaves=32,n_estimators=350,learning_rate=0.1,min_child_samples=8,max_depth=16,colsample_bytree=0.6)\n",
    "\n",
    "LGB.fit(X_train_16,y_train_16)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5344, 96)\n",
      "(5344,)\n",
      "(1336, 96)\n",
      "(1336,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_16.shape)\n",
    "print(y_train_16.shape)\n",
    "print(X_test_16.shape)\n",
    "print(y_test_16.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred_LGB = LGB.predict(X_test_16)\n",
    "np.savetxt('y_pred_LGB', y_pred_LGB, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  3.414431437935909\n",
      "MAE:  0.6685860538471078\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE: \",mean_squared_error(y_test_16, y_pred_LGB))\n",
    "print(\"MAE: \", mean_absolute_error(y_test_16, y_pred_LGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round\n",
    "y_1_LGB = np.around(y_pred_LGB)\n",
    "y_1_LGB = y_1_LGB.astype(int)\n",
    "np.savetxt('y_1_LGB', y_1_LGB, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a6737cef08>]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# difference between prediction and label\n",
    "diff_LGB = abs(y_1_LGB-y_test_16)\n",
    "np.savetxt('diff_LGB', diff_LGB, delimiter=',')\n",
    "plt.plot(diff_LGB, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7732035928143712"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# direct accuracy\n",
    "(len(diff_LGB) - np.count_nonzero(diff_LGB))/len(diff_LGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a673c8d208>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# <=5 then 0\n",
    "round_diff_LGB = np.zeros(len(y_test_16))\n",
    "for i in range(len(y_test_16)):\n",
    "    if abs(y_1_LGB[i]-y_test_16[i])<=5:\n",
    "        round_diff_LGB[i] = 0\n",
    "    else:\n",
    "        round_diff_LGB[i] = abs(y_1_LGB[i]-y_test_16[i])\n",
    "# plt.subplot(122)\n",
    "plt.plot(round_diff_LGB, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9745508982035929"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# +- 5 pixels are regarded as correctly-classified\n",
    "1-np.count_nonzero(round_diff_LGB)/len(y_test_16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict those samples with inner wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1476 1476\n",
      "MSE:  0.9737147595785007\n",
      "MAE:  0.4529205128821133\n"
     ]
    }
   ],
   "source": [
    "X_IW = []\n",
    "y_IW = []\n",
    "MSE_IW = []\n",
    "MAE_IW = []\n",
    "\n",
    "for i in range(len(y)):\n",
    "    if y[i]!=0:\n",
    "        X_IW.append(X_6v[i])\n",
    "        y_IW.append(y[i])\n",
    "print(len(X_IW), len(y_IW))\n",
    "\n",
    "for i in range(10):\n",
    "    X_train_16, X_test_16, y_train_16, y_test_16 = train_test_split( X_IW, y_IW, test_size=0.2)\n",
    "\n",
    "    scaler=StandardScaler()\n",
    "    X_train_16=scaler.fit_transform(X_train_16)\n",
    "    X_test_16=scaler.transform(X_test_16)\n",
    "\n",
    "    LGB = LGBMRegressor(n_jobs=-1,num_leaves=32,n_estimators=350,learning_rate=0.1,min_child_samples=8,max_depth=20,colsample_bytree=0.6)\n",
    "\n",
    "    LGB.fit(X_train_16,y_train_16)\n",
    "    \n",
    "    y_pred_IW = LGB.predict(X_test_16)\n",
    "    MSE_IW.append(mean_squared_error(y_test_16, y_pred_IW))\n",
    "    MAE_IW.append(mean_absolute_error(y_test_16, y_pred_IW))\n",
    "\n",
    "print(\"MSE: \", np.mean(MSE_IW))\n",
    "print(\"MAE: \", np.mean(MAE_IW))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9867698615069781"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(np.mean(MSE_IW))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formal Test x10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ±5pixels error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :\n",
      "MSE:  3.5945400322219903\n",
      "MAE:  0.6673846843725741\n",
      "acc:  0.9745508982035929\n",
      "Direct accuracy:  0.7866766467065869\n",
      "\n",
      "\n",
      "1 :\n",
      "MSE:  4.039763778146911\n",
      "MAE:  0.7083323366021179\n",
      "acc:  0.9715568862275449\n",
      "Direct accuracy:  0.7627245508982036\n",
      "\n",
      "\n",
      "2 :\n",
      "MSE:  3.220737631883959\n",
      "MAE:  0.6453163258407577\n",
      "acc:  0.9730538922155688\n",
      "Direct accuracy:  0.7784431137724551\n",
      "\n",
      "\n",
      "3 :\n",
      "MSE:  3.170406364149271\n",
      "MAE:  0.6574961927386035\n",
      "acc:  0.9738023952095809\n",
      "Direct accuracy:  0.7679640718562875\n",
      "\n",
      "\n",
      "4 :\n",
      "MSE:  4.142300702296581\n",
      "MAE:  0.7557617372829959\n",
      "acc:  0.9738023952095809\n",
      "Direct accuracy:  0.7447604790419161\n",
      "\n",
      "\n",
      "5 :\n",
      "MSE:  3.9611573484618594\n",
      "MAE:  0.7799488642185298\n",
      "acc:  0.967814371257485\n",
      "Direct accuracy:  0.7447604790419161\n",
      "\n",
      "\n",
      "6 :\n",
      "MSE:  3.2176917580363753\n",
      "MAE:  0.68065893934182\n",
      "acc:  0.9708083832335329\n",
      "Direct accuracy:  0.7747005988023952\n",
      "\n",
      "\n",
      "7 :\n",
      "MSE:  3.561035272465593\n",
      "MAE:  0.6980499942392075\n",
      "acc:  0.967814371257485\n",
      "Direct accuracy:  0.7672155688622755\n",
      "\n",
      "\n",
      "8 :\n",
      "MSE:  4.699130343880163\n",
      "MAE:  0.7817253845349439\n",
      "acc:  0.9610778443113772\n",
      "Direct accuracy:  0.7679640718562875\n",
      "\n",
      "\n",
      "9 :\n",
      "MSE:  3.683518765340395\n",
      "MAE:  0.713813473777254\n",
      "acc:  0.9738023952095809\n",
      "Direct accuracy:  0.7619760479041916\n",
      "\n",
      "\n",
      "10 :\n",
      "MSE:  3.7232175833639745\n",
      "MAE:  0.7003324639443347\n",
      "acc:  0.9797904191616766\n",
      "Direct accuracy:  0.7544910179640718\n",
      "\n",
      "\n",
      "11 :\n",
      "MSE:  4.669178312719605\n",
      "MAE:  0.7689526160493102\n",
      "acc:  0.9610778443113772\n",
      "Direct accuracy:  0.7791916167664671\n",
      "\n",
      "\n",
      "12 :\n",
      "MSE:  3.267750953446853\n",
      "MAE:  0.6905293350910531\n",
      "acc:  0.9760479041916168\n",
      "Direct accuracy:  0.7574850299401198\n",
      "\n",
      "\n",
      "13 :\n",
      "MSE:  3.464515310526932\n",
      "MAE:  0.681858995872647\n",
      "acc:  0.9738023952095809\n",
      "Direct accuracy:  0.7739520958083832\n",
      "\n",
      "\n",
      "14 :\n",
      "MSE:  3.5368738550427508\n",
      "MAE:  0.6936446470525801\n",
      "acc:  0.9775449101796407\n",
      "Direct accuracy:  0.7642215568862275\n",
      "\n",
      "\n",
      "15 :\n",
      "MSE:  4.2794102129887355\n",
      "MAE:  0.749245998694895\n",
      "acc:  0.968562874251497\n",
      "Direct accuracy:  0.7649700598802395\n",
      "\n",
      "\n",
      "16 :\n",
      "MSE:  3.3586473458720887\n",
      "MAE:  0.6748739501654359\n",
      "acc:  0.9797904191616766\n",
      "Direct accuracy:  0.749251497005988\n",
      "\n",
      "\n",
      "17 :\n",
      "MSE:  3.0509914393106308\n",
      "MAE:  0.6474236512110143\n",
      "acc:  0.9760479041916168\n",
      "Direct accuracy:  0.7732035928143712\n",
      "\n",
      "\n",
      "18 :\n",
      "MSE:  3.635536525470836\n",
      "MAE:  0.718648903809643\n",
      "acc:  0.9715568862275449\n",
      "Direct accuracy:  0.7567365269461078\n",
      "\n",
      "\n",
      "19 :\n",
      "MSE:  4.028327070186775\n",
      "MAE:  0.7239451102104052\n",
      "acc:  0.9738023952095809\n",
      "Direct accuracy:  0.7717065868263473\n",
      "\n",
      "\n",
      "20 :\n",
      "MSE:  4.325168332957876\n",
      "MAE:  0.7927521899003185\n",
      "acc:  0.9625748502994012\n",
      "Direct accuracy:  0.7447604790419161\n",
      "\n",
      "\n",
      "21 :\n",
      "MSE:  2.982459838297424\n",
      "MAE:  0.637457475917259\n",
      "acc:  0.9782934131736527\n",
      "Direct accuracy:  0.7619760479041916\n",
      "\n",
      "\n",
      "22 :\n",
      "MSE:  3.2214358826408334\n",
      "MAE:  0.667045354744661\n",
      "acc:  0.9760479041916168\n",
      "Direct accuracy:  0.7567365269461078\n",
      "\n",
      "\n",
      "23 :\n",
      "MSE:  3.6104171802206944\n",
      "MAE:  0.732562344911942\n",
      "acc:  0.9595808383233533\n",
      "Direct accuracy:  0.782185628742515\n",
      "\n",
      "\n",
      "24 :\n",
      "MSE:  4.199930373080303\n",
      "MAE:  0.7550575691697019\n",
      "acc:  0.9723053892215568\n",
      "Direct accuracy:  0.7522455089820359\n",
      "\n",
      "\n",
      "25 :\n",
      "MSE:  3.670864606983827\n",
      "MAE:  0.6995469241564161\n",
      "acc:  0.9723053892215568\n",
      "Direct accuracy:  0.7589820359281437\n",
      "\n",
      "\n",
      "26 :\n",
      "MSE:  4.287569792007121\n",
      "MAE:  0.7771687020921502\n",
      "acc:  0.9640718562874252\n",
      "Direct accuracy:  0.7425149700598802\n",
      "\n",
      "\n",
      "27 :\n",
      "MSE:  3.2222046169481158\n",
      "MAE:  0.6502167542927867\n",
      "acc:  0.9738023952095809\n",
      "Direct accuracy:  0.7896706586826348\n",
      "\n",
      "\n",
      "28 :\n",
      "MSE:  3.8726513508508993\n",
      "MAE:  0.7025220084883372\n",
      "acc:  0.968562874251497\n",
      "Direct accuracy:  0.7754491017964071\n",
      "\n",
      "\n",
      "29 :\n",
      "MSE:  3.171248311831418\n",
      "MAE:  0.6263614283701932\n",
      "acc:  0.9760479041916168\n",
      "Direct accuracy:  0.7949101796407185\n",
      "\n",
      "\n",
      "30 :\n",
      "MSE:  3.566090151451108\n",
      "MAE:  0.7201395529417235\n",
      "acc:  0.9663173652694611\n",
      "Direct accuracy:  0.7657185628742516\n",
      "\n",
      "\n",
      "31 :\n",
      "MSE:  3.5933374930900586\n",
      "MAE:  0.7067951372426348\n",
      "acc:  0.9723053892215568\n",
      "Direct accuracy:  0.7702095808383234\n",
      "\n",
      "\n",
      "32 :\n",
      "MSE:  3.903514164648857\n",
      "MAE:  0.7485195630087776\n",
      "acc:  0.967814371257485\n",
      "Direct accuracy:  0.7357784431137725\n",
      "\n",
      "\n",
      "33 :\n",
      "MSE:  3.7248369836354334\n",
      "MAE:  0.7187466666501944\n",
      "acc:  0.9723053892215568\n",
      "Direct accuracy:  0.7574850299401198\n",
      "\n",
      "\n",
      "34 :\n",
      "MSE:  3.2893804505488267\n",
      "MAE:  0.646315612790079\n",
      "acc:  0.9775449101796407\n",
      "Direct accuracy:  0.7717065868263473\n",
      "\n",
      "\n",
      "35 :\n",
      "MSE:  3.4069353727818976\n",
      "MAE:  0.662306661168974\n",
      "acc:  0.9745508982035929\n",
      "Direct accuracy:  0.7694610778443114\n",
      "\n",
      "\n",
      "36 :\n",
      "MSE:  3.353922904897547\n",
      "MAE:  0.671892153086469\n",
      "acc:  0.9760479041916168\n",
      "Direct accuracy:  0.7739520958083832\n",
      "\n",
      "\n",
      "37 :\n",
      "MSE:  4.684630761891474\n",
      "MAE:  0.7743427239945951\n",
      "acc:  0.967814371257485\n",
      "Direct accuracy:  0.7582335329341318\n",
      "\n",
      "\n",
      "38 :\n",
      "MSE:  4.354619207311696\n",
      "MAE:  0.8074370749218657\n",
      "acc:  0.9640718562874252\n",
      "Direct accuracy:  0.7417664670658682\n",
      "\n",
      "\n",
      "39 :\n",
      "MSE:  3.3031636466379\n",
      "MAE:  0.6549717580548244\n",
      "acc:  0.9790419161676647\n",
      "Direct accuracy:  0.7874251497005988\n",
      "\n",
      "\n",
      "40 :\n",
      "MSE:  3.390552999695108\n",
      "MAE:  0.6680196654992474\n",
      "acc:  0.9708083832335329\n",
      "Direct accuracy:  0.780688622754491\n",
      "\n",
      "\n",
      "41 :\n",
      "MSE:  3.8940740977727297\n",
      "MAE:  0.7189925345067801\n",
      "acc:  0.9648203592814372\n",
      "Direct accuracy:  0.7619760479041916\n",
      "\n",
      "\n",
      "42 :\n",
      "MSE:  5.046902998282605\n",
      "MAE:  0.8314256262880194\n",
      "acc:  0.9663173652694611\n",
      "Direct accuracy:  0.7432634730538922\n",
      "\n",
      "\n",
      "43 :\n",
      "MSE:  2.9886314315031504\n",
      "MAE:  0.6486613680395608\n",
      "acc:  0.9782934131736527\n",
      "Direct accuracy:  0.7649700598802395\n",
      "\n",
      "\n",
      "44 :\n",
      "MSE:  4.751570021571756\n",
      "MAE:  0.784618317355444\n",
      "acc:  0.968562874251497\n",
      "Direct accuracy:  0.7567365269461078\n",
      "\n",
      "\n",
      "45 :\n",
      "MSE:  3.239627743818876\n",
      "MAE:  0.6689240392207173\n",
      "acc:  0.9812874251497006\n",
      "Direct accuracy:  0.7717065868263473\n",
      "\n",
      "\n",
      "46 :\n",
      "MSE:  4.1167396233124105\n",
      "MAE:  0.7323823162998792\n",
      "acc:  0.968562874251497\n",
      "Direct accuracy:  0.7717065868263473\n",
      "\n",
      "\n",
      "47 :\n",
      "MSE:  4.80715366569164\n",
      "MAE:  0.8130254685797285\n",
      "acc:  0.9648203592814372\n",
      "Direct accuracy:  0.7574850299401198\n",
      "\n",
      "\n",
      "48 :\n",
      "MSE:  3.258521459810119\n",
      "MAE:  0.670078383765816\n",
      "acc:  0.9782934131736527\n",
      "Direct accuracy:  0.7604790419161677\n",
      "\n",
      "\n",
      "49 :\n",
      "MSE:  3.9683989808023474\n",
      "MAE:  0.7185425599017927\n",
      "acc:  0.9723053892215568\n",
      "Direct accuracy:  0.7627245508982036\n",
      "\n",
      "\n",
      "50 :\n",
      "MSE:  4.193872199791146\n",
      "MAE:  0.7518209433925969\n",
      "acc:  0.9723053892215568\n",
      "Direct accuracy:  0.7440119760479041\n",
      "\n",
      "\n",
      "51 :\n",
      "MSE:  4.352996034288502\n",
      "MAE:  0.7189511030782687\n",
      "acc:  0.9663173652694611\n",
      "Direct accuracy:  0.7761976047904192\n",
      "\n",
      "\n",
      "52 :\n",
      "MSE:  4.054268066309601\n",
      "MAE:  0.7271414580107121\n",
      "acc:  0.9752994011976048\n",
      "Direct accuracy:  0.7642215568862275\n",
      "\n",
      "\n",
      "53 :\n",
      "MSE:  4.24513729466919\n",
      "MAE:  0.7541188147782074\n",
      "acc:  0.9708083832335329\n",
      "Direct accuracy:  0.7552395209580839\n",
      "\n",
      "\n",
      "54 :\n",
      "MSE:  3.4447807206071674\n",
      "MAE:  0.6996349547082388\n",
      "acc:  0.9745508982035929\n",
      "Direct accuracy:  0.7604790419161677\n",
      "\n",
      "\n",
      "55 :\n",
      "MSE:  4.846327976486648\n",
      "MAE:  0.7986413959018553\n",
      "acc:  0.9648203592814372\n",
      "Direct accuracy:  0.7597305389221557\n",
      "\n",
      "\n",
      "56 :\n",
      "MSE:  3.669322591521736\n",
      "MAE:  0.6861749021764462\n",
      "acc:  0.9715568862275449\n",
      "Direct accuracy:  0.7687125748502994\n",
      "\n",
      "\n",
      "57 :\n",
      "MSE:  4.3908817682507175\n",
      "MAE:  0.7355629153213291\n",
      "acc:  0.9640718562874252\n",
      "Direct accuracy:  0.7619760479041916\n",
      "\n",
      "\n",
      "58 :\n",
      "MSE:  2.8134866244407424\n",
      "MAE:  0.6285274632091843\n",
      "acc:  0.9805389221556886\n",
      "Direct accuracy:  0.7724550898203593\n",
      "\n",
      "\n",
      "59 :\n",
      "MSE:  3.7894706728986387\n",
      "MAE:  0.6976640490121447\n",
      "acc:  0.9700598802395209\n",
      "Direct accuracy:  0.7784431137724551\n",
      "\n",
      "\n",
      "60 :\n",
      "MSE:  3.3273973485064188\n",
      "MAE:  0.6864373656726857\n",
      "acc:  0.9760479041916168\n",
      "Direct accuracy:  0.7604790419161677\n",
      "\n",
      "\n",
      "61 :\n",
      "MSE:  3.8648365425681086\n",
      "MAE:  0.7692486948711892\n",
      "acc:  0.9708083832335329\n",
      "Direct accuracy:  0.7402694610778443\n",
      "\n",
      "\n",
      "62 :\n",
      "MSE:  4.350643566460251\n",
      "MAE:  0.7535312002637319\n",
      "acc:  0.967814371257485\n",
      "Direct accuracy:  0.7604790419161677\n",
      "\n",
      "\n",
      "63 :\n",
      "MSE:  4.022582866679398\n",
      "MAE:  0.7368331057505491\n",
      "acc:  0.968562874251497\n",
      "Direct accuracy:  0.7642215568862275\n",
      "\n",
      "\n",
      "64 :\n",
      "MSE:  3.401249389246271\n",
      "MAE:  0.6701192849702682\n",
      "acc:  0.9745508982035929\n",
      "Direct accuracy:  0.7694610778443114\n",
      "\n",
      "\n",
      "65 :\n",
      "MSE:  4.133951875033185\n",
      "MAE:  0.7496493891938881\n",
      "acc:  0.9655688622754491\n",
      "Direct accuracy:  0.7582335329341318\n",
      "\n",
      "\n",
      "66 :\n",
      "MSE:  4.299365857944824\n",
      "MAE:  0.7845800810282781\n",
      "acc:  0.9655688622754491\n",
      "Direct accuracy:  0.7477544910179641\n",
      "\n",
      "\n",
      "67 :\n",
      "MSE:  4.053238668914638\n",
      "MAE:  0.750685246907207\n",
      "acc:  0.9708083832335329\n",
      "Direct accuracy:  0.7552395209580839\n",
      "\n",
      "\n",
      "68 :\n",
      "MSE:  3.9060629882405524\n",
      "MAE:  0.7307977546619889\n",
      "acc:  0.9670658682634731\n",
      "Direct accuracy:  0.7739520958083832\n",
      "\n",
      "\n",
      "69 :\n",
      "MSE:  3.9437879651945766\n",
      "MAE:  0.7336910030882842\n",
      "acc:  0.9723053892215568\n",
      "Direct accuracy:  0.7627245508982036\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 :\n",
      "MSE:  3.60938376750353\n",
      "MAE:  0.7198572797384122\n",
      "acc:  0.9708083832335329\n",
      "Direct accuracy:  0.7642215568862275\n",
      "\n",
      "\n",
      "71 :\n",
      "MSE:  3.742468720085315\n",
      "MAE:  0.7146965540840585\n",
      "acc:  0.9715568862275449\n",
      "Direct accuracy:  0.7672155688622755\n",
      "\n",
      "\n",
      "72 :\n",
      "MSE:  3.689508945795956\n",
      "MAE:  0.6835539920911909\n",
      "acc:  0.9730538922155688\n",
      "Direct accuracy:  0.7619760479041916\n",
      "\n",
      "\n",
      "73 :\n",
      "MSE:  3.707697814030026\n",
      "MAE:  0.7169299151848398\n",
      "acc:  0.9700598802395209\n",
      "Direct accuracy:  0.7589820359281437\n",
      "\n",
      "\n",
      "74 :\n",
      "MSE:  4.063824817262301\n",
      "MAE:  0.7052231806920264\n",
      "acc:  0.9723053892215568\n",
      "Direct accuracy:  0.7612275449101796\n",
      "\n",
      "\n",
      "75 :\n",
      "MSE:  3.4985315523414546\n",
      "MAE:  0.679239771728783\n",
      "acc:  0.968562874251497\n",
      "Direct accuracy:  0.780688622754491\n",
      "\n",
      "\n",
      "76 :\n",
      "MSE:  2.7823860087844356\n",
      "MAE:  0.6240750102204387\n",
      "acc:  0.9797904191616766\n",
      "Direct accuracy:  0.7672155688622755\n",
      "\n",
      "\n",
      "77 :\n",
      "MSE:  3.1450807027735452\n",
      "MAE:  0.6354795338644833\n",
      "acc:  0.9775449101796407\n",
      "Direct accuracy:  0.7747005988023952\n",
      "\n",
      "\n",
      "78 :\n",
      "MSE:  3.754728446586306\n",
      "MAE:  0.7074469100610133\n",
      "acc:  0.9730538922155688\n",
      "Direct accuracy:  0.7597305389221557\n",
      "\n",
      "\n",
      "79 :\n",
      "MSE:  3.820103563844308\n",
      "MAE:  0.7226668352286268\n",
      "acc:  0.9730538922155688\n",
      "Direct accuracy:  0.7619760479041916\n",
      "\n",
      "\n",
      "80 :\n",
      "MSE:  4.436011244563205\n",
      "MAE:  0.7668845367025556\n",
      "acc:  0.9708083832335329\n",
      "Direct accuracy:  0.7627245508982036\n",
      "\n",
      "\n",
      "81 :\n",
      "MSE:  4.035454397472699\n",
      "MAE:  0.7078740160868618\n",
      "acc:  0.9715568862275449\n",
      "Direct accuracy:  0.7761976047904192\n",
      "\n",
      "\n",
      "82 :\n",
      "MSE:  3.6648939196730037\n",
      "MAE:  0.7100806584599684\n",
      "acc:  0.9745508982035929\n",
      "Direct accuracy:  0.7619760479041916\n",
      "\n",
      "\n",
      "83 :\n",
      "MSE:  4.939628789266281\n",
      "MAE:  0.7592597681177423\n",
      "acc:  0.9640718562874252\n",
      "Direct accuracy:  0.782185628742515\n",
      "\n",
      "\n",
      "84 :\n",
      "MSE:  3.54538621829314\n",
      "MAE:  0.7203736853096914\n",
      "acc:  0.9760479041916168\n",
      "Direct accuracy:  0.7612275449101796\n",
      "\n",
      "\n",
      "85 :\n",
      "MSE:  3.8350928937921154\n",
      "MAE:  0.7007117576557094\n",
      "acc:  0.9745508982035929\n",
      "Direct accuracy:  0.7769461077844312\n",
      "\n",
      "\n",
      "86 :\n",
      "MSE:  3.3954212045862366\n",
      "MAE:  0.6685665826627788\n",
      "acc:  0.9767964071856288\n",
      "Direct accuracy:  0.7634730538922155\n",
      "\n",
      "\n",
      "87 :\n",
      "MSE:  3.6910159118691412\n",
      "MAE:  0.7349648609755142\n",
      "acc:  0.9723053892215568\n",
      "Direct accuracy:  0.750748502994012\n",
      "\n",
      "\n",
      "88 :\n",
      "MSE:  3.9577868656490285\n",
      "MAE:  0.7373928209376387\n",
      "acc:  0.9700598802395209\n",
      "Direct accuracy:  0.7627245508982036\n",
      "\n",
      "\n",
      "89 :\n",
      "MSE:  3.9747743033744323\n",
      "MAE:  0.7525758140453557\n",
      "acc:  0.968562874251497\n",
      "Direct accuracy:  0.7612275449101796\n",
      "\n",
      "\n",
      "90 :\n",
      "MSE:  3.742060971015546\n",
      "MAE:  0.6971531103737374\n",
      "acc:  0.9708083832335329\n",
      "Direct accuracy:  0.7874251497005988\n",
      "\n",
      "\n",
      "91 :\n",
      "MSE:  3.852648377063\n",
      "MAE:  0.6993511601966574\n",
      "acc:  0.9752994011976048\n",
      "Direct accuracy:  0.7597305389221557\n",
      "\n",
      "\n",
      "92 :\n",
      "MSE:  3.1338384527456866\n",
      "MAE:  0.6854451165483363\n",
      "acc:  0.9730538922155688\n",
      "Direct accuracy:  0.7455089820359282\n",
      "\n",
      "\n",
      "93 :\n",
      "MSE:  4.5613510217862245\n",
      "MAE:  0.7916739037112561\n",
      "acc:  0.9700598802395209\n",
      "Direct accuracy:  0.7544910179640718\n",
      "\n",
      "\n",
      "94 :\n",
      "MSE:  4.480658779369381\n",
      "MAE:  0.7312064103739503\n",
      "acc:  0.9700598802395209\n",
      "Direct accuracy:  0.7709580838323353\n",
      "\n",
      "\n",
      "95 :\n",
      "MSE:  4.278602773178297\n",
      "MAE:  0.7467319248520525\n",
      "acc:  0.968562874251497\n",
      "Direct accuracy:  0.7672155688622755\n",
      "\n",
      "\n",
      "96 :\n",
      "MSE:  4.953637085133787\n",
      "MAE:  0.8343681430487037\n",
      "acc:  0.9625748502994012\n",
      "Direct accuracy:  0.7402694610778443\n",
      "\n",
      "\n",
      "97 :\n",
      "MSE:  4.043912917291053\n",
      "MAE:  0.7338583894123417\n",
      "acc:  0.9723053892215568\n",
      "Direct accuracy:  0.7687125748502994\n",
      "\n",
      "\n",
      "98 :\n",
      "MSE:  2.9456547644223945\n",
      "MAE:  0.6489642116209468\n",
      "acc:  0.9738023952095809\n",
      "Direct accuracy:  0.781437125748503\n",
      "\n",
      "\n",
      "99 :\n",
      "MSE:  3.3459951325134876\n",
      "MAE:  0.694675326072244\n",
      "acc:  0.9723053892215568\n",
      "Direct accuracy:  0.7732035928143712\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LGB_Acc = []\n",
    "\n",
    "for i in range(### ±3pixels error100):\n",
    "    X_train_16, X_test_16, y_train_16, y_test_16 = train_test_split( X_6v, y, test_size=0.2)\n",
    "\n",
    "    scaler=StandardScaler()\n",
    "    X_train_16=scaler.fit_transform(X_train_16)\n",
    "    X_test_16=scaler.transform(X_test_16)\n",
    "\n",
    "    # max_depth=20\n",
    "    LGB = LGBMRegressor(n_jobs=-1,num_leaves=32,n_estimators=350,learning_rate=0.1,min_child_samples=8,max_depth=16,colsample_bytree=0.6)\n",
    "\n",
    "    LGB.fit(X_train_16,y_train_16)\n",
    "\n",
    "    # predict\n",
    "    y_pred_LGB = LGB.predict(X_test_16)\n",
    "    print(i, \":\")\n",
    "    print(\"MSE: \",mean_squared_error(y_test_16, y_pred_LGB))\n",
    "    print(\"MAE: \", mean_absolute_error(y_test_16, y_pred_LGB))\n",
    "\n",
    "    # round\n",
    "    y_1_LGB = np.around(y_pred_LGB)\n",
    "    y_1_LGB = y_1_LGB.astype(int)\n",
    "\n",
    "    # difference between prediction and label\n",
    "    diff_LGB = abs(y_1_LGB-y_test_16)\n",
    "\n",
    "    # <=5 then 0\n",
    "    round_diff_LGB = np.zeros(len(y_test_16))\n",
    "    for i in range(len(y_test_16)):\n",
    "        if abs(y_1_LGB[i]-y_test_16[i])<=5:\n",
    "            round_diff_LGB[i] = 0\n",
    "        else:\n",
    "            round_diff_LGB[i] = abs(y_1_LGB[i]-y_test_16[i])\n",
    "\n",
    "    # +- 5 pixels are regarded as correctly-classified\n",
    "    acc_LGB = 1-np.count_nonzero(round_diff_LGB)/len(y_test_16)\n",
    "    print(\"acc: \", acc_LGB)\n",
    "    # direct accuracy\n",
    "    print(\"Direct accuracy: \",(len(diff_LGB) - np.count_nonzero(diff_LGB))/len(diff_LGB))\n",
    "    print(\"\\n\")\n",
    "    LGB_Acc.append(acc_LGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9714895209580839\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(LGB_Acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ±3pixels error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :\n",
      "MSE:  3.7728516779701473\n",
      "MAE:  0.7238912219831459\n",
      "acc:  0.9476047904191617\n",
      "Direct accuracy:  0.7552395209580839\n",
      "\n",
      "\n",
      "1 :\n",
      "MSE:  3.650879860633836\n",
      "MAE:  0.7099415749785993\n",
      "acc:  0.9476047904191617\n",
      "Direct accuracy:  0.7649700598802395\n",
      "\n",
      "\n",
      "2 :\n",
      "MSE:  3.3291429966412434\n",
      "MAE:  0.6591073732817045\n",
      "acc:  0.9520958083832335\n",
      "Direct accuracy:  0.7649700598802395\n",
      "\n",
      "\n",
      "3 :\n",
      "MSE:  2.9902154474929956\n",
      "MAE:  0.6676114845989825\n",
      "acc:  0.9491017964071856\n",
      "Direct accuracy:  0.7597305389221557\n",
      "\n",
      "\n",
      "4 :\n",
      "MSE:  3.7988532121106076\n",
      "MAE:  0.6787681559439205\n",
      "acc:  0.9505988023952096\n",
      "Direct accuracy:  0.7799401197604791\n",
      "\n",
      "\n",
      "5 :\n",
      "MSE:  3.3828002906642625\n",
      "MAE:  0.6846804460442498\n",
      "acc:  0.9528443113772456\n",
      "Direct accuracy:  0.7642215568862275\n",
      "\n",
      "\n",
      "6 :\n",
      "MSE:  4.090474370554802\n",
      "MAE:  0.7889648694899744\n",
      "acc:  0.9438622754491018\n",
      "Direct accuracy:  0.7417664670658682\n",
      "\n",
      "\n",
      "7 :\n",
      "MSE:  4.048623591731736\n",
      "MAE:  0.7272163538787905\n",
      "acc:  0.9461077844311377\n",
      "Direct accuracy:  0.7664670658682635\n",
      "\n",
      "\n",
      "8 :\n",
      "MSE:  2.9039514539736464\n",
      "MAE:  0.6302519386278794\n",
      "acc:  0.9565868263473054\n",
      "Direct accuracy:  0.7754491017964071\n",
      "\n",
      "\n",
      "9 :\n",
      "MSE:  3.141094213725845\n",
      "MAE:  0.6817376674325525\n",
      "acc:  0.9408682634730539\n",
      "Direct accuracy:  0.7672155688622755\n",
      "\n",
      "\n",
      "10 :\n",
      "MSE:  3.9091069248794565\n",
      "MAE:  0.7080350963171339\n",
      "acc:  0.9446107784431138\n",
      "Direct accuracy:  0.7754491017964071\n",
      "\n",
      "\n",
      "11 :\n",
      "MSE:  3.280338193005919\n",
      "MAE:  0.6714842911656383\n",
      "acc:  0.9543413173652695\n",
      "Direct accuracy:  0.7687125748502994\n",
      "\n",
      "\n",
      "12 :\n",
      "MSE:  3.561013361616417\n",
      "MAE:  0.720090332988952\n",
      "acc:  0.9461077844311377\n",
      "Direct accuracy:  0.7559880239520959\n",
      "\n",
      "\n",
      "13 :\n",
      "MSE:  4.015616036388651\n",
      "MAE:  0.7717094724985366\n",
      "acc:  0.938622754491018\n",
      "Direct accuracy:  0.7552395209580839\n",
      "\n",
      "\n",
      "14 :\n",
      "MSE:  3.7489233878173236\n",
      "MAE:  0.680894454208957\n",
      "acc:  0.9513473053892215\n",
      "Direct accuracy:  0.7844311377245509\n",
      "\n",
      "\n",
      "15 :\n",
      "MSE:  4.263882822857808\n",
      "MAE:  0.7291663883363386\n",
      "acc:  0.9513473053892215\n",
      "Direct accuracy:  0.7627245508982036\n",
      "\n",
      "\n",
      "16 :\n",
      "MSE:  4.74949873474211\n",
      "MAE:  0.7973884089351557\n",
      "acc:  0.9408682634730539\n",
      "Direct accuracy:  0.7372754491017964\n",
      "\n",
      "\n",
      "17 :\n",
      "MSE:  3.854903832615245\n",
      "MAE:  0.7250125933448076\n",
      "acc:  0.9446107784431138\n",
      "Direct accuracy:  0.7672155688622755\n",
      "\n",
      "\n",
      "18 :\n",
      "MSE:  4.718869651975582\n",
      "MAE:  0.7754810594365312\n",
      "acc:  0.9476047904191617\n",
      "Direct accuracy:  0.7627245508982036\n",
      "\n",
      "\n",
      "19 :\n",
      "MSE:  4.3270259866910425\n",
      "MAE:  0.7607913469544294\n",
      "acc:  0.9453592814371258\n",
      "Direct accuracy:  0.7589820359281437\n",
      "\n",
      "\n",
      "20 :\n",
      "MSE:  4.425478236904308\n",
      "MAE:  0.7421842223081765\n",
      "acc:  0.9468562874251497\n",
      "Direct accuracy:  0.7739520958083832\n",
      "\n",
      "\n",
      "21 :\n",
      "MSE:  3.0405482498165814\n",
      "MAE:  0.6454570921630759\n",
      "acc:  0.9528443113772456\n",
      "Direct accuracy:  0.7739520958083832\n",
      "\n",
      "\n",
      "22 :\n",
      "MSE:  4.160232699101218\n",
      "MAE:  0.7565134530612538\n",
      "acc:  0.9431137724550899\n",
      "Direct accuracy:  0.7589820359281437\n",
      "\n",
      "\n",
      "23 :\n",
      "MSE:  3.7407846426199693\n",
      "MAE:  0.7119867395609899\n",
      "acc:  0.9453592814371258\n",
      "Direct accuracy:  0.7694610778443114\n",
      "\n",
      "\n",
      "24 :\n",
      "MSE:  4.755451637858067\n",
      "MAE:  0.7842522662677588\n",
      "acc:  0.9431137724550899\n",
      "Direct accuracy:  0.7679640718562875\n",
      "\n",
      "\n",
      "25 :\n",
      "MSE:  3.48560981740517\n",
      "MAE:  0.7244173494641907\n",
      "acc:  0.9408682634730539\n",
      "Direct accuracy:  0.7679640718562875\n",
      "\n",
      "\n",
      "26 :\n",
      "MSE:  3.1582040740740704\n",
      "MAE:  0.654168707940897\n",
      "acc:  0.9543413173652695\n",
      "Direct accuracy:  0.7694610778443114\n",
      "\n",
      "\n",
      "27 :\n",
      "MSE:  3.470746551554268\n",
      "MAE:  0.6954808830197075\n",
      "acc:  0.9476047904191617\n",
      "Direct accuracy:  0.7687125748502994\n",
      "\n",
      "\n",
      "28 :\n",
      "MSE:  4.555680729380419\n",
      "MAE:  0.7574880412016426\n",
      "acc:  0.9491017964071856\n",
      "Direct accuracy:  0.7702095808383234\n",
      "\n",
      "\n",
      "29 :\n",
      "MSE:  3.3987976415005443\n",
      "MAE:  0.7210380974359446\n",
      "acc:  0.9461077844311377\n",
      "Direct accuracy:  0.7574850299401198\n",
      "\n",
      "\n",
      "30 :\n",
      "MSE:  3.5772270827273545\n",
      "MAE:  0.6804596913855813\n",
      "acc:  0.9483532934131736\n",
      "Direct accuracy:  0.7687125748502994\n",
      "\n",
      "\n",
      "31 :\n",
      "MSE:  3.2647905053448802\n",
      "MAE:  0.6786181339898142\n",
      "acc:  0.9476047904191617\n",
      "Direct accuracy:  0.7709580838323353\n",
      "\n",
      "\n",
      "32 :\n",
      "MSE:  3.5060339326689998\n",
      "MAE:  0.676260173103939\n",
      "acc:  0.9528443113772456\n",
      "Direct accuracy:  0.7844311377245509\n",
      "\n",
      "\n",
      "33 :\n",
      "MSE:  3.439067684800935\n",
      "MAE:  0.6992818332973478\n",
      "acc:  0.9468562874251497\n",
      "Direct accuracy:  0.7567365269461078\n",
      "\n",
      "\n",
      "34 :\n",
      "MSE:  3.957628611643227\n",
      "MAE:  0.6999777186164025\n",
      "acc:  0.9558383233532934\n",
      "Direct accuracy:  0.7582335329341318\n",
      "\n",
      "\n",
      "35 :\n",
      "MSE:  5.745222583984973\n",
      "MAE:  0.89304393068106\n",
      "acc:  0.9281437125748503\n",
      "Direct accuracy:  0.7327844311377245\n",
      "\n",
      "\n",
      "36 :\n",
      "MSE:  3.130212676114679\n",
      "MAE:  0.6335019991394412\n",
      "acc:  0.9580838323353293\n",
      "Direct accuracy:  0.7911676646706587\n",
      "\n",
      "\n",
      "37 :\n",
      "MSE:  4.179177883664697\n",
      "MAE:  0.7247573103488679\n",
      "acc:  0.9446107784431138\n",
      "Direct accuracy:  0.7739520958083832\n",
      "\n",
      "\n",
      "38 :\n",
      "MSE:  3.9537206238837133\n",
      "MAE:  0.7289658138176005\n",
      "acc:  0.9446107784431138\n",
      "Direct accuracy:  0.7619760479041916\n",
      "\n",
      "\n",
      "39 :\n",
      "MSE:  3.4361629588545983\n",
      "MAE:  0.705477084253943\n",
      "acc:  0.9446107784431138\n",
      "Direct accuracy:  0.7597305389221557\n",
      "\n",
      "\n",
      "40 :\n",
      "MSE:  2.8524618269643933\n",
      "MAE:  0.623494990141996\n",
      "acc:  0.9625748502994012\n",
      "Direct accuracy:  0.7709580838323353\n",
      "\n",
      "\n",
      "41 :\n",
      "MSE:  4.224228394759645\n",
      "MAE:  0.7368781491065425\n",
      "acc:  0.9498502994011976\n",
      "Direct accuracy:  0.7582335329341318\n",
      "\n",
      "\n",
      "42 :\n",
      "MSE:  4.936512121189098\n",
      "MAE:  0.7970429061299731\n",
      "acc:  0.937125748502994\n",
      "Direct accuracy:  0.7717065868263473\n",
      "\n",
      "\n",
      "43 :\n",
      "MSE:  4.354825588230185\n",
      "MAE:  0.7659257453851228\n",
      "acc:  0.9423652694610778\n",
      "Direct accuracy:  0.7537425149700598\n",
      "\n",
      "\n",
      "44 :\n",
      "MSE:  4.207641928170655\n",
      "MAE:  0.7297250467734043\n",
      "acc:  0.9476047904191617\n",
      "Direct accuracy:  0.7776946107784432\n",
      "\n",
      "\n",
      "45 :\n",
      "MSE:  4.2261706102406125\n",
      "MAE:  0.7627945781795541\n",
      "acc:  0.9393712574850299\n",
      "Direct accuracy:  0.7470059880239521\n",
      "\n",
      "\n",
      "46 :\n",
      "MSE:  3.8360420652816813\n",
      "MAE:  0.6844388012038961\n",
      "acc:  0.9550898203592815\n",
      "Direct accuracy:  0.7724550898203593\n",
      "\n",
      "\n",
      "47 :\n",
      "MSE:  4.124951879439683\n",
      "MAE:  0.7482104095063138\n",
      "acc:  0.9461077844311377\n",
      "Direct accuracy:  0.7589820359281437\n",
      "\n",
      "\n",
      "48 :\n",
      "MSE:  4.029659881557186\n",
      "MAE:  0.7623916332618312\n",
      "acc:  0.9468562874251497\n",
      "Direct accuracy:  0.7462574850299402\n",
      "\n",
      "\n",
      "49 :\n",
      "MSE:  4.208044699002276\n",
      "MAE:  0.7367383928192749\n",
      "acc:  0.9468562874251497\n",
      "Direct accuracy:  0.7559880239520959\n",
      "\n",
      "\n",
      "50 :\n",
      "MSE:  5.642726109219924\n",
      "MAE:  0.8663708457481109\n",
      "acc:  0.9326347305389222\n",
      "Direct accuracy:  0.7455089820359282\n",
      "\n",
      "\n",
      "51 :\n",
      "MSE:  3.427708573395126\n",
      "MAE:  0.6757341344641214\n",
      "acc:  0.9446107784431138\n",
      "Direct accuracy:  0.7784431137724551\n",
      "\n",
      "\n",
      "52 :\n",
      "MSE:  3.23981262066937\n",
      "MAE:  0.6548696938676273\n",
      "acc:  0.9573353293413174\n",
      "Direct accuracy:  0.7642215568862275\n",
      "\n",
      "\n",
      "53 :\n",
      "MSE:  3.3857375313172553\n",
      "MAE:  0.6788138712464481\n",
      "acc:  0.9505988023952096\n",
      "Direct accuracy:  0.7649700598802395\n",
      "\n",
      "\n",
      "54 :\n",
      "MSE:  3.4980550649744577\n",
      "MAE:  0.6845656392741464\n",
      "acc:  0.9461077844311377\n",
      "Direct accuracy:  0.7799401197604791\n",
      "\n",
      "\n",
      "55 :\n",
      "MSE:  4.280002924012798\n",
      "MAE:  0.7228236702006535\n",
      "acc:  0.9483532934131736\n",
      "Direct accuracy:  0.7754491017964071\n",
      "\n",
      "\n",
      "56 :\n",
      "MSE:  3.2037574326518103\n",
      "MAE:  0.6894491799923173\n",
      "acc:  0.9468562874251497\n",
      "Direct accuracy:  0.7604790419161677\n",
      "\n",
      "\n",
      "57 :\n",
      "MSE:  4.869756209777695\n",
      "MAE:  0.7833981893698625\n",
      "acc:  0.9438622754491018\n",
      "Direct accuracy:  0.7522455089820359\n",
      "\n",
      "\n",
      "58 :\n",
      "MSE:  3.2334443284562133\n",
      "MAE:  0.6604590418924405\n",
      "acc:  0.9580838323353293\n",
      "Direct accuracy:  0.7791916167664671\n",
      "\n",
      "\n",
      "59 :\n",
      "MSE:  5.02588435736264\n",
      "MAE:  0.8266627845353649\n",
      "acc:  0.938622754491018\n",
      "Direct accuracy:  0.7544910179640718\n",
      "\n",
      "\n",
      "60 :\n",
      "MSE:  4.594682836153067\n",
      "MAE:  0.8018080966595722\n",
      "acc:  0.9393712574850299\n",
      "Direct accuracy:  0.7485029940119761\n",
      "\n",
      "\n",
      "61 :\n",
      "MSE:  4.392118464985515\n",
      "MAE:  0.7268618550875405\n",
      "acc:  0.9513473053892215\n",
      "Direct accuracy:  0.7747005988023952\n",
      "\n",
      "\n",
      "62 :\n",
      "MSE:  4.425308104279476\n",
      "MAE:  0.7469291458797981\n",
      "acc:  0.9416167664670658\n",
      "Direct accuracy:  0.7724550898203593\n",
      "\n",
      "\n",
      "63 :\n",
      "MSE:  4.445227953740416\n",
      "MAE:  0.7640916213127878\n",
      "acc:  0.9468562874251497\n",
      "Direct accuracy:  0.7552395209580839\n",
      "\n",
      "\n",
      "64 :\n",
      "MSE:  3.8885957839142034\n",
      "MAE:  0.7218965729660869\n",
      "acc:  0.9505988023952096\n",
      "Direct accuracy:  0.7694610778443114\n",
      "\n",
      "\n",
      "65 :\n",
      "MSE:  4.403429635111243\n",
      "MAE:  0.7544320062774944\n",
      "acc:  0.9491017964071856\n",
      "Direct accuracy:  0.7462574850299402\n",
      "\n",
      "\n",
      "66 :\n",
      "MSE:  3.6800081570458656\n",
      "MAE:  0.7158482248323961\n",
      "acc:  0.9423652694610778\n",
      "Direct accuracy:  0.7664670658682635\n",
      "\n",
      "\n",
      "67 :\n",
      "MSE:  3.8879465752281144\n",
      "MAE:  0.7527218404744846\n",
      "acc:  0.9401197604790419\n",
      "Direct accuracy:  0.7514970059880239\n",
      "\n",
      "\n",
      "68 :\n",
      "MSE:  3.78735638410508\n",
      "MAE:  0.709397045961636\n",
      "acc:  0.9401197604790419\n",
      "Direct accuracy:  0.7709580838323353\n",
      "\n",
      "\n",
      "69 :\n",
      "MSE:  3.1996138862813055\n",
      "MAE:  0.6760757588781467\n",
      "acc:  0.9498502994011976\n",
      "Direct accuracy:  0.7627245508982036\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 :\n",
      "MSE:  3.6535198315248194\n",
      "MAE:  0.7291836127174093\n",
      "acc:  0.9498502994011976\n",
      "Direct accuracy:  0.7395209580838323\n",
      "\n",
      "\n",
      "71 :\n",
      "MSE:  3.982627384707925\n",
      "MAE:  0.7472847210216851\n",
      "acc:  0.9461077844311377\n",
      "Direct accuracy:  0.7470059880239521\n",
      "\n",
      "\n",
      "72 :\n",
      "MSE:  3.634357956271198\n",
      "MAE:  0.74992328728253\n",
      "acc:  0.9438622754491018\n",
      "Direct accuracy:  0.7529940119760479\n",
      "\n",
      "\n",
      "73 :\n",
      "MSE:  4.001010698332032\n",
      "MAE:  0.7565671722704553\n",
      "acc:  0.9483532934131736\n",
      "Direct accuracy:  0.749251497005988\n",
      "\n",
      "\n",
      "74 :\n",
      "MSE:  4.318782643049067\n",
      "MAE:  0.7913797826632321\n",
      "acc:  0.9333832335329342\n",
      "Direct accuracy:  0.7537425149700598\n",
      "\n",
      "\n",
      "75 :\n",
      "MSE:  3.249878434803532\n",
      "MAE:  0.6619226114714782\n",
      "acc:  0.9573353293413174\n",
      "Direct accuracy:  0.782185628742515\n",
      "\n",
      "\n",
      "76 :\n",
      "MSE:  3.8102264870564952\n",
      "MAE:  0.7515171673356307\n",
      "acc:  0.9393712574850299\n",
      "Direct accuracy:  0.7567365269461078\n",
      "\n",
      "\n",
      "77 :\n",
      "MSE:  3.4063024705378804\n",
      "MAE:  0.6721233532744701\n",
      "acc:  0.9476047904191617\n",
      "Direct accuracy:  0.780688622754491\n",
      "\n",
      "\n",
      "78 :\n",
      "MSE:  3.4171883068936966\n",
      "MAE:  0.6939613840598592\n",
      "acc:  0.9498502994011976\n",
      "Direct accuracy:  0.7627245508982036\n",
      "\n",
      "\n",
      "79 :\n",
      "MSE:  4.102098136305084\n",
      "MAE:  0.7268363320970579\n",
      "acc:  0.9491017964071856\n",
      "Direct accuracy:  0.7604790419161677\n",
      "\n",
      "\n",
      "80 :\n",
      "MSE:  3.7198525102787636\n",
      "MAE:  0.6996926514371431\n",
      "acc:  0.9438622754491018\n",
      "Direct accuracy:  0.7784431137724551\n",
      "\n",
      "\n",
      "81 :\n",
      "MSE:  4.3277473755066715\n",
      "MAE:  0.7859280035061703\n",
      "acc:  0.938622754491018\n",
      "Direct accuracy:  0.7477544910179641\n",
      "\n",
      "\n",
      "82 :\n",
      "MSE:  3.9413754980165456\n",
      "MAE:  0.7172064687373789\n",
      "acc:  0.9498502994011976\n",
      "Direct accuracy:  0.7784431137724551\n",
      "\n",
      "\n",
      "83 :\n",
      "MSE:  3.478529854710828\n",
      "MAE:  0.701464398911327\n",
      "acc:  0.9505988023952096\n",
      "Direct accuracy:  0.7574850299401198\n",
      "\n",
      "\n",
      "84 :\n",
      "MSE:  3.743885034159073\n",
      "MAE:  0.7284722701775473\n",
      "acc:  0.9446107784431138\n",
      "Direct accuracy:  0.7567365269461078\n",
      "\n",
      "\n",
      "85 :\n",
      "MSE:  3.7739555942251166\n",
      "MAE:  0.6977909534424335\n",
      "acc:  0.9476047904191617\n",
      "Direct accuracy:  0.780688622754491\n",
      "\n",
      "\n",
      "86 :\n",
      "MSE:  4.308357707689854\n",
      "MAE:  0.7383886314344047\n",
      "acc:  0.9446107784431138\n",
      "Direct accuracy:  0.7732035928143712\n",
      "\n",
      "\n",
      "87 :\n",
      "MSE:  3.8156807172141884\n",
      "MAE:  0.7367501103968838\n",
      "acc:  0.9408682634730539\n",
      "Direct accuracy:  0.7709580838323353\n",
      "\n",
      "\n",
      "88 :\n",
      "MSE:  3.306991937740804\n",
      "MAE:  0.6655956970144523\n",
      "acc:  0.9543413173652695\n",
      "Direct accuracy:  0.7739520958083832\n",
      "\n",
      "\n",
      "89 :\n",
      "MSE:  3.5316434002902293\n",
      "MAE:  0.6846415270785334\n",
      "acc:  0.9565868263473054\n",
      "Direct accuracy:  0.7761976047904192\n",
      "\n",
      "\n",
      "90 :\n",
      "MSE:  3.7233449389254534\n",
      "MAE:  0.7071054647964392\n",
      "acc:  0.9476047904191617\n",
      "Direct accuracy:  0.7709580838323353\n",
      "\n",
      "\n",
      "91 :\n",
      "MSE:  3.753262279579457\n",
      "MAE:  0.6937891327302438\n",
      "acc:  0.9453592814371258\n",
      "Direct accuracy:  0.781437125748503\n",
      "\n",
      "\n",
      "92 :\n",
      "MSE:  4.318109521521424\n",
      "MAE:  0.7674987054303003\n",
      "acc:  0.9423652694610778\n",
      "Direct accuracy:  0.7529940119760479\n",
      "\n",
      "\n",
      "93 :\n",
      "MSE:  4.860458208061264\n",
      "MAE:  0.7731442456699644\n",
      "acc:  0.9423652694610778\n",
      "Direct accuracy:  0.7694610778443114\n",
      "\n",
      "\n",
      "94 :\n",
      "MSE:  3.680123148749451\n",
      "MAE:  0.7222748064898703\n",
      "acc:  0.9483532934131736\n",
      "Direct accuracy:  0.7470059880239521\n",
      "\n",
      "\n",
      "95 :\n",
      "MSE:  3.1824319797438148\n",
      "MAE:  0.6528153273689571\n",
      "acc:  0.9543413173652695\n",
      "Direct accuracy:  0.781437125748503\n",
      "\n",
      "\n",
      "96 :\n",
      "MSE:  4.864584071805382\n",
      "MAE:  0.7999827853384619\n",
      "acc:  0.937874251497006\n",
      "Direct accuracy:  0.7724550898203593\n",
      "\n",
      "\n",
      "97 :\n",
      "MSE:  3.3281907621294318\n",
      "MAE:  0.6742353801666527\n",
      "acc:  0.9528443113772456\n",
      "Direct accuracy:  0.7672155688622755\n",
      "\n",
      "\n",
      "98 :\n",
      "MSE:  4.195158866279014\n",
      "MAE:  0.7689420151972004\n",
      "acc:  0.9401197604790419\n",
      "Direct accuracy:  0.7522455089820359\n",
      "\n",
      "\n",
      "99 :\n",
      "MSE:  3.683305357910376\n",
      "MAE:  0.736762235031916\n",
      "acc:  0.9453592814371258\n",
      "Direct accuracy:  0.7470059880239521\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LGB_Acc_3 = []\n",
    "\n",
    "for i in range(100):\n",
    "    X_train_16, X_test_16, y_train_16, y_test_16 = train_test_split( X_6v, y, test_size=0.2)\n",
    "\n",
    "    scaler=StandardScaler()\n",
    "    X_train_16=scaler.fit_transform(X_train_16)\n",
    "    X_test_16=scaler.transform(X_test_16)\n",
    "\n",
    "    # max_depth=20\n",
    "    LGB = LGBMRegressor(n_jobs=-1,num_leaves=32,n_estimators=350,learning_rate=0.1,min_child_samples=8,max_depth=16,colsample_bytree=0.6)\n",
    "\n",
    "    LGB.fit(X_train_16,y_train_16)\n",
    "\n",
    "    # predict\n",
    "    y_pred_LGB = LGB.predict(X_test_16)\n",
    "    print(i, \":\")\n",
    "    print(\"MSE: \",mean_squared_error(y_test_16, y_pred_LGB))\n",
    "    print(\"MAE: \", mean_absolute_error(y_test_16, y_pred_LGB))\n",
    "\n",
    "    # round\n",
    "    y_1_LGB = np.around(y_pred_LGB)\n",
    "    y_1_LGB = y_1_LGB.astype(int)\n",
    "\n",
    "    # difference between prediction and label\n",
    "    diff_LGB = abs(y_1_LGB-y_test_16)\n",
    "\n",
    "    # <=3 then 0\n",
    "    round_diff_LGB = np.zeros(len(y_test_16))\n",
    "    for i in range(len(y_test_16)):\n",
    "        if abs(y_1_LGB[i]-y_test_16[i])<=3:\n",
    "            round_diff_LGB[i] = 0\n",
    "        else:\n",
    "            round_diff_LGB[i] = abs(y_1_LGB[i]-y_test_16[i])\n",
    "\n",
    "    # +- 3 pixels are regarded as correctly-classified\n",
    "    acc_LGB_3 = 1-np.count_nonzero(round_diff_LGB)/len(y_test_16)\n",
    "    print(\"acc: \", acc_LGB_3)\n",
    "    # direct accuracy\n",
    "    print(\"Direct accuracy: \",(len(diff_LGB) - np.count_nonzero(diff_LGB))/len(diff_LGB))\n",
    "    print(\"\\n\")\n",
    "    LGB_Acc_3.append(acc_LGB_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9467814371257484\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(LGB_Acc_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "isbcq5jLWkch"
   },
   "source": [
    "# NNRegressor - TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv - 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gm_eP94zWne6"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential,activations\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import BatchNormalization,Dropout,Dense,Flatten,Conv1D,Conv2D,MaxPooling1D,MaxPooling2D,GlobalMaxPooling2D,AveragePooling2D,Activation,Input,Add,Dense,ZeroPadding2D,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.models import Model\n",
    "from keras import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xOs_o76OWqvM"
   },
   "outputs": [],
   "source": [
    "def plotLearningCurve(history,epochs):\n",
    "  epochRange = range(1,epochs+1)\n",
    "  plt.plot(epochRange,history.history['accuracy'])\n",
    "  plt.plot(epochRange,history.history['val_accuracy'])\n",
    "  plt.title('Model Accuracy')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.legend(['Train','Validation'],loc='upper left')\n",
    "  plt.show()\n",
    "\n",
    "  plt.plot(epochRange,history.history['loss'])\n",
    "  plt.plot(epochRange,history.history['val_loss'])\n",
    "  plt.title('Model Loss')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.legend(['Train','Validation'],loc='upper left')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HEYtzN9xWz27"
   },
   "outputs": [],
   "source": [
    "# ====================TODO=====================\n",
    "\n",
    "data_2D = np.load(\"/content/drive/My Drive/Colab Notebooks/patch/data_2D.npz\")\n",
    "\n",
    "X_2D = data_2D[\"arr_0\"]\n",
    "y_2D = data_2D[\"arr_1\"]\n",
    "\n",
    "X_2D[np.isnan(X_2D)]=0\n",
    "y_2D[np.isnan(y_2D)]=0\n",
    "\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(X_2D, y_2D, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# X_train_3 = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "# X_test_3 = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "print(X_train_3.shape)\n",
    "print(X_test_3.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EOqWWrpEW2Pv"
   },
   "outputs": [],
   "source": [
    "# ====================TODO=====================\n",
    "\n",
    "model_3=Sequential()\n",
    "model_3.add(Conv2D(filters=16,kernel_size=(3,3),activation='relu',input_shape=X_train_3[0].shape,kernel_regularizer='l2',kernel_initializer=\"he_uniform\",padding=\"same\"))\n",
    "model_3.add(BatchNormalization())\n",
    "# model_3.add(MaxPooling2D())\n",
    "\n",
    "model_3.add(Conv2D(filters=32,kernel_size=(3,3),activation='relu',kernel_regularizer='l2',kernel_initializer=\"he_uniform\",padding=\"same\"))\n",
    "model_3.add(BatchNormalization())\n",
    "# model_3.add(MaxPooling2D())\n",
    "\n",
    "model_3.add(Conv2D(filters=64,kernel_size=(3,3),activation='relu',kernel_regularizer='l2',kernel_initializer=\"he_uniform\",padding=\"same\"))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(MaxPooling2D())\n",
    "\n",
    "model_3.add(Conv2D(filters=128,kernel_size=(3,3),activation='relu',kernel_regularizer='l2',kernel_initializer=\"he_uniform\",padding=\"same\"))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(MaxPooling2D())\n",
    "\n",
    "model_3.add(Conv2D(filters=256,kernel_size=(3,3),activation='relu',kernel_regularizer='l2',kernel_initializer=\"he_uniform\",padding=\"same\"))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(MaxPooling2D())\n",
    "\n",
    "model_3.add(Flatten())\n",
    "model_3.add(Dense(64,activation='relu',kernel_regularizer='l2',kernel_initializer=\"he_uniform\"))\n",
    "model_3.add(Dropout(0.2))\n",
    "model_3.add(Dense(32,activation='relu',kernel_regularizer='l2',kernel_initializer=\"he_uniform\"))\n",
    "model_3.add(Dropout(0.2))\n",
    "model_3.add(Dense(16,activation='relu',kernel_regularizer='l2',kernel_initializer=\"he_uniform\"))\n",
    "# model.add(Dropout(0.1))\n",
    "model_3.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Conv2D"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "IW-Experiment-16.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
